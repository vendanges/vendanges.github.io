<!DOCTYPE html>
<html>

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta name="theme-color" content="#33474d">
	<title>琼瑶</title>
	<link rel="stylesheet" href="/css/style.css" />
	
      <link rel="alternate" href="/atom.xml" title="琼瑶" type="application/atom+xml">
    
<meta name="generator" content="Hexo 6.1.0"></head>

<body>

	<header class="header">
		<nav class="header__nav">
			
				<a href="/" class="header__link" style="color: #fff">Home</a>
			
				<a href="/archives" class="header__link" style="color: #fff">Archive</a>
			
				<a href="/about" class="header__link" style="color: #fff">About</a>
			
		</nav>
		<!-- <h1 class="header__title"><a href="/">琼瑶</a></h1> -->
		<h1 class="header__title"><a href="/"><img style="width: 290px;" src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/202204152017786.png"></a></h1>
		<h2 class="header__subtitle">梦入琼楼寒有月，行过石树冻无烟</h2>
	</header>

	<main>
		
	<span class="different-posts different-posts_earlier">📖 <a href="/page/20">earlier posts</a> 📖</span>




	<article>
	
		<h1><a href="/2022/04/21/exe/1.Vagrant 概述/">Vagrant</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a> <a class="article__tag-none-link" href="/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/" rel="tag">虚拟机</a>
			</span>
		
	</div>

	

	
		<p>Vagrant 最早通过 Mitchell Hashimoto 因业余兴趣而发布使用 Ruby lang 所实现的一种基于构建及配置虚拟开发环境工具，主要依赖 VirtualBox、 VMware、Libvirt 等虚拟化系统来实现快速部署开发环境的构建。</p>
<p>通过由 Oracle 所开源的 VirtualBox 虚拟化系统，受其开源所带来的好处可配合 Vagrant 来快速构建虚拟环境，这让 Vagrant + VirtualBox 这种组合更加的流行且成为了生产力工具之一。</p>
<h2 id="install"><a href="#install" class="headerlink" title="install"></a>install</h2><p>安装 Vagrant 本身不怎么麻烦，但是对于没有 Ruby 环境的读者以及虚拟依赖可能非常困惑，特别是 VirtualBox 依赖的问题。</p>
<p>如果通过 dpkg 进行安装很可能安装不到 VirtualBox 的依赖，因此我们需要手动进行安装依赖（VirtualBox &gt;&#x3D; 6.0）：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install build-essentials</span><br><span class="line">sudo apt-get install virtualbox-ose</span><br><span class="line">sudo /sbin/vboxconfig</span><br><span class="line">sudo apt-get install dkms build-essential linux-headers-`uname -r`</span><br></pre></td></tr></table></figure>

<h2 id="Box"><a href="#Box" class="headerlink" title="Box"></a>Box</h2><p>vagrant box 主要的作用最多的就是管理当前的 box，包括安装、移除等。等 vagrant 安装完成之后就开始到了我们的使用环节，通常我们最常用的就是添加一个 Vagrant box：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant init [name[,url]</span><br></pre></td></tr></table></figure>

<p>当执行完 <code>init</code> 后，则当前目录已经初始化为 Vagrant 环境，就比如我们可以使用：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vagrant init kalilinux/rolling</span><br></pre></td></tr></table></figure>

<p>如果要删除框，首先需要查询框，通过 <code>vagrant box list</code> 来查询目前所拥有的框，我们可以通过使用下述命令删除：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">vagrant box remove kalilinux/rolling</span></span><br><span class="line">Removing box &#x27;kalilinux/rolling&#x27; (v2021.2.0) with provider &#x27;virtualbox&#x27;...</span><br></pre></td></tr></table></figure>

<p>而 <code>kalilinux/rolling</code> 则是通过使用 <code>vagrant box list </code> 所得出的信息。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/exe/1.redmine/">redmine</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/%E5%B7%A5%E5%85%B7/" rel="tag">工具</a> <a class="article__tag-none-link" href="/tags/%E9%A1%B9%E7%9B%AE%E7%AE%A1%E7%90%86/" rel="tag">项目管理</a>
			</span>
		
	</div>

	

	
		<p>Redmine 是一个基于Web项目的管理和权限管理和跟踪工具，与其他主流的项目管理平台不同的是 Redmine 是一个开源的。它用日历和甘特图辅助项目及进度可视化显示。同时它又支持多项目管理。Redmine 是一个自由开放 源码软件解决方案，它提供集成的项目管理功能，问题跟踪，并为多个版本控制选项的支持。需要注意的是 Redmine 是建立在 Ruby and Rails 的框架之上，因此他支持跨平台和多种数据库，但是缺点是安装的过程会非常折腾。</p>
<h2 id="安装-redmine"><a href="#安装-redmine" class="headerlink" title="安装 redmine"></a>安装 redmine</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><p>最新版的 redmine 可以通过<a target="_blank" rel="noopener" href="https://www.redmine.org/projects/redmine/wiki/RedmineInstall#Step-9-Test-the-installation">https://www.redmine.org/projects/redmine/wiki/RedmineInstall#Step-9-Test-the-installation</a> 内进行下载，本文使用 <strong>4.0.9 (2021-04-26)</strong> 作为演示。</p>
<blockquote>
<p>需要注意的是下面的所有步骤均在 redmine 文件下进行（除了你 ruby 编译安装）</p>
</blockquote>
<h4 id="mysql"><a href="#mysql" class="headerlink" title="mysql"></a>mysql</h4><p>首先按照 redmine 官方文档的意思是，我们需要创建一个 <strong>redmine</strong> 的用户，并创建一个 <strong>redmine</strong> 库，为了让操作变得简单我们忽略<strong>新建用户</strong>的这个步骤，需们需要创建一个库：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">create database redmine</span><br></pre></td></tr></table></figure>
<p>当然你如果非常讲究我们也可以根据官方文档中一样，创建一个 redmine 用户：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CREATE DATABASE redmine CHARACTER SET utf8mb4;</span><br><span class="line">CREATE USER &#x27;redmine&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;my_password&#x27;;</span><br><span class="line">GRANT ALL PRIVILEGES ON redmine.* TO &#x27;redmine&#x27;@&#x27;localhost&#x27;;</span><br></pre></td></tr></table></figure>

<h5 id="redmine"><a href="#redmine" class="headerlink" title="redmine"></a>redmine</h5><p>之后进入到 <code>redmine-4.0.9/config</code>目录，之后将 <strong>database.yml.example</strong> 文件下的 <code>production</code> 复制到 <strong>database.yml</strong>文件下（需要创建一个 database.yml）</p>
<figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">production:</span></span><br><span class="line">  <span class="attr">adapter:</span> <span class="string">mysql2</span></span><br><span class="line">  <span class="attr">database:</span> <span class="string">redmine</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">localhost</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">username</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">&quot;password&quot;</span></span><br><span class="line">  <span class="attr">encoding:</span> <span class="string">utf8</span></span><br></pre></td></tr></table></figure>
<p>此时也是一个必然的过程，你还需要修改 <code>production</code>内的<code>username、password</code>等信息，来配置你的数据库<strong>帐号密码</strong>。</p>
<h3 id="ruby"><a href="#ruby" class="headerlink" title="ruby"></a>ruby</h3><p>值得注意的是 redmine 所依赖的 <strong>ruby&amp;gem and bundle</strong> 如果你选择使用 <strong>MySQL</strong>数据库作为数据存储方式的话还需要有一个 MySQL 的环境。通常在 debian 的系统中已经内置了<strong>ruby&amp;gem</strong> 的语言环境，如果没有您还需要执行 <code>apt-get install ruby</code>来进行安装，如果您已经存在了<strong>ruby&amp;gem</strong>则不需要重新安装。</p>
<h4 id="自动安装"><a href="#自动安装" class="headerlink" title="自动安装"></a>自动安装</h4><p>本文使用的 <code>ruby</code>版本为<strong>2.5.5p157</strong>，gem 的版本为 <strong>3.2.16</strong>，通常 gem 版本可通过使用<code>gem update --system</code>直接进行升级，但需要注意的是</p>
<h4 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h4><p>本文基于 debian bunsen labs 发行版进行演示，通常除了<strong>Arch Linux</strong>系的系统基本上都可以进行安装，需要注意的是由于 Arch Linux 滚动更新的缘故，因此他的软件包都非常的新。</p>
<p>现在是 2021年05月11日，此时 debian 系官方提供的 ruby 版本是 2019-03-15 所发布的<strong>2.5.5p157</strong>版本，而此时的 Arch Linux 可能已经用上了前年，即<strong>2020-12-25</strong>所发布的 <strong>ruby 3.0</strong>了，而值得庆幸的是 redmine 也支持 ruby 3.0：</p>
<table>
<thead>
<tr>
<th>redmine 版本</th>
<th>支持的 ruby 版本</th>
<th>使用的 rails 版本</th>
</tr>
</thead>
<tbody><tr>
<td>trunk (&gt;&#x3D; r20913)</td>
<td>Ruby 2.5, 2.6, 2.7, 3.0</td>
<td>Rails 6.1</td>
</tr>
<tr>
<td>4.2</td>
<td>Ruby 2.4, 2.5, 2.6, 2.7</td>
<td>Rails 5.2</td>
</tr>
<tr>
<td>4.1</td>
<td>Ruby 2.3, 2.4, 2.5, 2.6</td>
<td>Rails 5.2</td>
</tr>
<tr>
<td>4.0</td>
<td>Ruby 2.2, 2.3, 2.4, 2.5, 2.6</td>
<td>Rails 5.2</td>
</tr>
</tbody></table>
<ol>
<li>Redmine 4.2不支持Ruby 2.7.0和2.7.1。使用Ruby 2.7.2或更高版本</li>
<li>24.0.6 之前的 Redmine 支持 Ruby &gt;&#x3D; 2.2.2。Redmine 4.0.6及更高版本不支持Ruby 2.2。</li>
</ol>
<h5 id="下载-amp-安装"><a href="#下载-amp-安装" class="headerlink" title="下载&amp;安装"></a>下载&amp;安装</h5><p>下载 ruby 2.4.2 版的压缩文件，更多全新版本你可以在 <a target="_blank" rel="noopener" href="https://cache.ruby-lang.org/pub/ruby/">https://cache.ruby-lang.org/pub/ruby/</a> 进行下载。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://cache.ruby-lang.org/pub/ruby/ruby-2.4.2.tar.gz</span><br></pre></td></tr></table></figure>

<p>之后解压并进入文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf ruby-2.4.2.tgz</span><br><span class="line">cd ruby-2.4.2</span><br></pre></td></tr></table></figure>

<p>进入后配置并编译源代码</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure>

<p>最后通过使用 <code>ruby -v</code>来验证是否安装成功，如果你本机中已经存在了 ruby或其他版本，您需要注意下安装的位置不要与其他版本冲突，否则你无论使用 <code>ruby&amp;gem</code>都会报错：<br><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210511110904.png"></p>
<p>如果遇到这个问题我会选择将所有 ruby 文件删除，只安装一个 ruby 版本。这个时候你 google 就会有人让你执行 <code>gem install bundler</code>，但是你换个思路想：“我执行 gem update 都报错了，我还能执行 gem install bundler 来安装 bundler 吗？”，很明显这个方法并不适用。如果你有其他的方法欢迎联系我 <a href="mailto:&#107;&#x6c;&#64;&#x73;&#x69;&#102;&#46;&#111;&#x6e;&#101;">&#107;&#x6c;&#64;&#x73;&#x69;&#102;&#46;&#111;&#x6e;&#101;</a>。</p>
<h3 id="gem"><a href="#gem" class="headerlink" title="gem"></a>gem</h3><p>RubyGem(gem)，是一个Ruby 的一个包管理器，他提供了一个分发 ruby 程序和库的标准格式，还提供了一个管理程序包的安装工具，类似于 npm、pip。</p>
<h4 id="配置源"><a href="#配置源" class="headerlink" title="配置源"></a>配置源</h4><p>RubyGems 一直以来在国内都非常难访问到，在本地你或许可以翻墙，当你要发布上线的时候，你就很难搞了。RubyGems 是由一个非常高端也非常有优越感的一个社区，他们为此提供了一个 Gem 的 CDN，来确保几乎无延迟的同步。</p>
<p>在本文中我们除了使用 RubyChina 所提供的 CDN，以及由 Ruby 官方社区所提供的 GemCDN 源，<a target="_blank" rel="noopener" href="https://rubygems.org/">https://rubygems.org/</a> 国内是可以访问的，因此我们<strong>不需要移出</strong>，只需要添加一个 <a target="_blank" rel="noopener" href="https://gems.ruby-china.com/">https://gems.ruby-china.com/</a> 源即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem sources -a https://gems.ruby-china.com/</span><br></pre></td></tr></table></figure>

<p>之后通过<code>gem sources</code>来查看源列表存在 <strong>rubychina</strong>社区所提供的源即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">gem source</span><br><span class="line">*** CURRENT SOURCES ***</span><br><span class="line"></span><br><span class="line">https://gems.ruby-china.com/</span><br><span class="line">https://rubygems.org/</span><br></pre></td></tr></table></figure>

<h4 id="bundler"><a href="#bundler" class="headerlink" title="bundler"></a>bundler</h4><h5 id="安装-amp-配置"><a href="#安装-amp-配置" class="headerlink" title="安装&amp;配置"></a>安装&amp;配置</h5><p>bundler 是一个能够跟踪并安装所需特定版本的 gem，以此来为 ruby 项目提供一致的运行环境，安装 bundler 安装的方式可以通过 gem 也可通过外部文件安装：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install bundler</span><br></pre></td></tr></table></figure>

<p>当然我们也可以制定安装 bundler 版本<strong>2.2.17</strong>，只需要在安装时指定版本即可：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gem install bundler:2.2.17</span><br></pre></td></tr></table></figure>

<p>安装完成后我们需要新的 bundle，来以防下面的操作报错。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bundle install</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在<code>bundler install</code>时你可能会出现两个错误</p>
<blockquote>
<p><strong>Gem::Ext::BuildError: ERROR: Failed to build gem native extension error</strong><br>gem install jaro_winkler -v ‘1.5.2’ –source ‘<a target="_blank" rel="noopener" href="https://cernerrepos.net/api/gems/rubygems/&#39;">https://cernerrepos.net/api/gems/rubygems/&#39;</a></p>
</blockquote>
<blockquote>
<p><strong>Gem::Installer::ExtensionBuildError: ERROR: Failed to build gem native extension.</strong><br>如果出现了这种错误我们需要通过 apt-get 安装 <code>install build-essential patch ruby-dev zlib1g-dev liblzma-dev</code>以及<code>nokogiri</code>等依赖：<br>sudo apt-get install build-essential patch ruby-dev zlib1g-dev liblzma-dev<br>gem install nokogiri</p>
</blockquote>
</blockquote>
<p>然后安装 redmine 所需的所有 gem 依赖：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bundle install --without development test</span><br></pre></td></tr></table></figure>

<p>接着我们来生成一个随机密钥，rails 使用他来编码存储会话数据的 cookies，从而防止被篡改（重新启动后生成的令牌将会使得现有会话无效）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bundle exec rake generate_secret_token</span><br></pre></td></tr></table></figure>

<h5 id="依赖项"><a href="#依赖项" class="headerlink" title="依赖项"></a>依赖项</h5><p>本文所使用的 redmine 4.2 版本，因此我们需要使用下面步骤来跳过 rmagick gem 的安装</p>
<blockquote>
<p>rmagick 对于 redmine 4.1.0 之前的版本主要用于将甘特图导出至 png 或 pdf 格式文件</p>
</blockquote>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bundle install --without development test rmagick</span><br></pre></td></tr></table></figure>

<h4 id="rails"><a href="#rails" class="headerlink" title="rails"></a>rails</h4><p>在上述配置 redmine 库的时候你可能非常疑问为什么又有新建表，因此在下面的步骤中会给你一个非常好的答案。我们在 redmine 项目下运行下述命令来创建数据结构：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAILS_ENV=production bundle exec rake db:migrate</span><br></pre></td></tr></table></figure>

<p>之后通过下属命令，在数据库中插入默认的配置数据：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RAILS_ENV=production bundle exec rake redmine:load_default_data</span><br></pre></td></tr></table></figure>

<h3 id="run"><a href="#run" class="headerlink" title="run"></a>run</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210511110704.png"><br>当上述步骤完成之后，我们可以试着通过下述命令运行 redmine:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bundle exec rails server webrick -e production</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在此时你可能还会遇到一个错误</p>
<blockquote>
<p>RubyGems warning&#x2F;error: Gem::Specification# default_executable &#x3D; is deprecated with no replacement. It will be removed</p>
</blockquote>
<blockquote>
<p>这是一个 RubyGem 团队的最新公告声明，这是在 RubyGem 1.8 之后才有的，因此我们需要通过使用下述命令进行更新。<br>gem pristine –all –no-extensions</p>
</blockquote>
</blockquote>
<p>当该命令运行成功后，我们可以通过使用<code>localhost:3000</code>进入到 redmine 页面，如果可以看到程序 view 则表示已经部署完成。可以通过使用 <code>admin\admin</code>来登入你的管理员帐号。</p>
<h1 id="redmine-run"><a href="#redmine-run" class="headerlink" title="redmine-run"></a>redmine-run</h1><p>读者在运行时可能非常迷惑 redmine 的启动命令太长而记不住，导致每次需要时都需要找到资料粘贴上去。因此为了解决这个问题国内开发者为此开发了 redmine-run 脚本来解决 redmien 启动的问题。</p>
<p>需要注意的是，此项目基于 <code>Linux 4.19.0-16-amd64 #1 SMP Debian 4.19.181-1 (2021-03-19) x86_64 GNU/Linux</code> 环境进行开发，<strong>理论</strong>上来讲系统只要存在<strong>ln</strong>以及<strong>mv</strong>和支持 <strong>.sh</strong> 脚本基本上就可以使用本项目。</p>
<p>通过使用 redmine run ，可以直接通过<code>redmine</code>来启动 redmine 项目管理平台，避免输入长且毫无规律的 <code>bundle exec rails server webrick -e production</code>，还需要进入到 redmine 目录中运行。</p>
<blockquote>
<p>下述操作需要全部使用 <strong>root</strong> 权限运行</p>
</blockquote>
<p>首先我们需要拉取 redmine run：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://gitee.com/analysis-of-river-snow/radmine-run.git</span><br></pre></td></tr></table></figure>

<p>将里面的 <strong>install.sh</strong>以及<strong>redmine.sh</strong>拖到 redmine <strong>目录中</strong></p>
<blockquote>
<p>redmine 目录即你可以执行<code>bundle exec rails server webrick -e production</code></p>
</blockquote>
<p>让 install.sh 和 redmine.sh 成为可执行文件:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 install.sh</span><br><span class="line">chmod 777 redmine.sh</span><br></pre></td></tr></table></figure>

<p>之后我们先修改 <strong>install.sh</strong> 文件内容，并将<code>/opt/redmine/redmine-4.0.9/</code>修改为你的 redmine 所在目录即可：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">cd /opt/redmine/redmine-4.0.9/</span><br><span class="line">redmine_run=`bundle exec rails server webrick -e production`</span><br><span class="line">echo &quot;[echo] 正在进入目录&quot; $path_use</span><br><span class="line">echo &quot;[echo] 执行 redmine run 命令 =&gt; bundle exec rails server webrick -e production&quot; $redmine_run</span><br></pre></td></tr></table></figure>

<p>然后执行<code>./install.sh</code>即可，之后通过使用<strong>redmine</strong> 来运行项目。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/redis/4.Redis 数据类型/">Redis 数据类型</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/redis/" rel="tag">redis</a>
			</span>
		
	</div>

	

	
		<p>Redis 中的数据类型主要分为 <strong>字符串、哈希、列表、集合、有序集合、HyperLogLog、地理信息、Stream</strong> 等类型，字符串类型在上一章我们就已经介绍过，他通过 <code>SET</code> 就可以直接进行创建，而其他的数据类型则是需要通过其他的命令以及其下属配合的命令来完成操作。</p>
<h2 id="哈希（Hash）"><a href="#哈希（Hash）" class="headerlink" title="哈希（Hash）"></a>哈希（Hash）</h2><p>哈希是一个 string 类型的 字段（field） 以及值（value）映射表，可适用与存储对象，单个哈希键值可存储多大40亿字段值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; HMSET hash_value name &quot;kun&quot; info &quot;hello,world&quot; url &quot;http://jiangxue.org.cn&quot; and &quot;one&quot; or &quot;two&quot; age &quot;17&quot; redis &quot;redislabs.com&quot;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; HGETALL hash_value</span><br><span class="line"> 1) &quot;name&quot;</span><br><span class="line"> 2) &quot;kun&quot;</span><br><span class="line"> 3) &quot;info&quot;</span><br><span class="line"> 4) &quot;hello,world&quot;</span><br><span class="line"> 5) &quot;url&quot;</span><br><span class="line"> 6) &quot;http://jiangxue.org.cn&quot;</span><br><span class="line"> 7) &quot;and&quot;</span><br><span class="line"> 8) &quot;one&quot;</span><br><span class="line"> 9) &quot;or&quot;</span><br><span class="line"> 10) &quot;two&quot;</span><br><span class="line"> 11) &quot;age&quot;</span><br><span class="line"> 12) &quot;17&quot;</span><br><span class="line"> 13) &quot;redis&quot;</span><br><span class="line"> 14) &quot;redislabs.com&quot;</span><br></pre></td></tr></table></figure>


<p>需要注意的是 Hashes 类型的字段依然是通过键值来进行存储的，如 <code>name=kun、info=hello,world</code> </p>
<p>可以通过使用 <code>HMSET</code> 来创建 hash 类型的键值对，也可以使用 <code>HGETALL</code> 来获取所有的字段值，当然也可以指定键名的方式来进行获取 <code>HGETALL hash_value &quot;name&quot;</code>。</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>HMSET</td>
<td>创建 hash 类型的键值段</td>
<td><code>HMSET hash_value name &quot;kun&quot; info &quot;hello,world&quot; url &quot;http://jiangxue.org.cn&quot;</code></td>
</tr>
<tr>
<td>2</td>
<td>HMGET</td>
<td>获取指定字段的值</td>
<td><code>HMGET hash_value name</code></td>
</tr>
<tr>
<td>2</td>
<td>HGET</td>
<td>获取存储在哈希表中指定的字段值</td>
<td><code>HGET hash_value &quot;name&quot;</code></td>
</tr>
<tr>
<td>3</td>
<td>HSET</td>
<td>自 redis 4.0 起可以一次性设置多个字段对，<code>HMSET</code> 区别是可以覆盖字段值</td>
<td><code>HSET hash_value age &quot;10&quot;</code></td>
</tr>
<tr>
<td>4</td>
<td>HSETNX</td>
<td>为哈希表中不存在的字段赋值（如存在返回 0）</td>
<td><code>HSETNX hash_value about &quot;jiangxue&quot;</code></td>
</tr>
<tr>
<td>5</td>
<td>HGETALL</td>
<td>获取全部或单个的 hash 类型键值段</td>
<td><code>HGETALL hash_value</code> or <code>HGET hash_value &quot;name&quot;</code></td>
</tr>
<tr>
<td>6</td>
<td>HEXISTS</td>
<td>查看哈希表中的 key 是否存在（存在返回 1，否则返回0）</td>
<td><code>HEXISTS hash_value &quot;name&quot;</code></td>
</tr>
<tr>
<td>7</td>
<td>HKEYS</td>
<td>获取当前所有哈希表中的字段</td>
<td><code>HKEYS hash_value</code></td>
</tr>
<tr>
<td>8</td>
<td>HVALS</td>
<td>获取当前所有哈希表中的字段值</td>
<td><code>HVALS hash_value</code></td>
</tr>
<tr>
<td>9</td>
<td>HLEN</td>
<td>获取哈希表中字段的数量（从1开始）</td>
<td><code>HLEN hash_value</code></td>
</tr>
<tr>
<td>10</td>
<td>HDEL</td>
<td>删除一个多多个哈希表中的键值对</td>
<td><code>HDEL hash_value &quot;and&quot; &quot;or&quot;</code></td>
</tr>
<tr>
<td>11</td>
<td>HINCRBY</td>
<td>为指定的哈希表中的 key 增加或减少数值（整数）</td>
<td><code>HINCRBY hash_value age 1</code> （原本 17将会被增加1，得出 18）</td>
</tr>
<tr>
<td>12</td>
<td>HINCRBYFLOAT</td>
<td>与 <code> HINCRBY</code> 的区别是支持非整数计算以及科学计数法</td>
<td><code> HINCRBYFLOAT hash_value age -1.5</code> （18-1.5 得出 16.5）</td>
</tr>
<tr>
<td>13</td>
<td>HSCAN</td>
<td>模糊搜索哈希表中的字段，并返回键值段</td>
<td><code>HSCAN hash_value 0 match &quot;na*&quot;</code> (返回 name 字段即值)</td>
</tr>
<tr>
<td>14</td>
<td>HSTRLEN</td>
<td>返回字段值的长度</td>
<td><code>HSTRLEN hash_value &quot;name&quot;</code></td>
</tr>
</tbody></table>
<h2 id="列表（List）"><a href="#列表（List）" class="headerlink" title="列表（List）"></a>列表（List）</h2><p>列表在 Redis 中表示可以将数据按顺序排序插入的字符串列表，通常可以包含超过40亿个元素，这启动主要通过 <code>LPUSH</code> 来插入一个或多个到列表头部，以及通过 <code>LRANGE</code> 来获取列表范围</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LPUSH list_key redis</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; LPUSH list_key mysql</span><br><span class="line">(integer) 2</span><br><span class="line">    127.0.0.1:6379&gt; LPUSH list_key sql</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; LPUSH list_key mongoDB</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; LPUSH list_key one two</span><br><span class="line">(integer) 6</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 10</span><br><span class="line">1) &quot;two&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;mongoDB&quot;</span><br><span class="line">4) &quot;sql&quot;</span><br><span class="line">5) &quot;mysql&quot;</span><br><span class="line">6) &quot;redis&quot;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>LPUSH</td>
<td>将一个或多个值插入到列表头部 (如果 key 不存在则会创建一个)</td>
<td><code>LPUSH list_key mongoDB</code></td>
</tr>
<tr>
<td>2</td>
<td>RPUSH</td>
<td>将一个或多个值插入到表尾部（如果 key 不存在则会创建一个）</td>
<td><code>RPUSH list_key &quot;nice!&quot;</code></td>
</tr>
<tr>
<td>3</td>
<td>LPUSHX</td>
<td>key 不存在时不进行任何操作并返回 0，存在的话则将值插入到列表头部</td>
<td><code> LPUSHX list_key &quot;hello&quot;</code></td>
</tr>
<tr>
<td>4</td>
<td>RPUSHX</td>
<td>key 不存在时不进行任何操作并返回 0，存在的话则将值插入到列表尾部</td>
<td><code>RPUSHX list_keys &quot;world&quot;</code></td>
</tr>
<tr>
<td>5</td>
<td>LINSERT</td>
<td>在指定元素前插入列表数据</td>
<td><code>LINSERT list_key BEFORE &quot;redis&quot; &quot;redislab.com&quot;</code> （在 redis 前插入 redislab.com）</td>
</tr>
<tr>
<td>6</td>
<td>LSET</td>
<td>通过索引替换列表元素（以0开始）</td>
<td><code>LSET list_key 0 &quot;start&quot;</code>（将 索引为0的元素替换为 “start”）</td>
</tr>
<tr>
<td>7</td>
<td>LRANGE</td>
<td>在一定范围内获取列表内元素</td>
<td><code>LRANGE list_key 0 100</code></td>
</tr>
<tr>
<td>8</td>
<td>LINDEX</td>
<td>返回指定索引对应的表内元素（超出范围返回 nill）</td>
<td><code>LINDEX list_key 0</code></td>
</tr>
<tr>
<td>9</td>
<td>BRPOPLPUSH</td>
<td>将指定列表内最后一个元素插入到另外一个列表的头部（如果列表没有元素会阻塞到超时为止，或者发现可以移出的元素为止，单位是秒，需要注意的是如果超时参数是 0 ，那么将会表示阻塞的时间可以无限期延长）</td>
<td><code>BRPOPLPUSH list_key key_name 500</code></td>
</tr>
<tr>
<td>10</td>
<td>LLEN</td>
<td>获取列表的元素数量</td>
<td><code>LLEN list_key</code></td>
</tr>
<tr>
<td>11</td>
<td>LTRIM</td>
<td>用于修建已经存在列表内的元素（要么从前删除要么从后删除，不可跨越索引）</td>
<td><code>LTRIM list_key -1 -1</code> （从倒数地一个开始，然后直到倒数第一个，也就是说之保留倒数地一个）</td>
</tr>
<tr>
<td>12</td>
<td>BLPOP</td>
<td>移出第一个列表元素，并返回所移出的列表名称和元素</td>
<td><code>BLPOP list_key 0</code></td>
</tr>
<tr>
<td>13</td>
<td>BRPOP</td>
<td>移出列表最后一个元素，同样返回岁移出的列表名和元素</td>
<td><code>LRANGE list_key 0 -1</code></td>
</tr>
<tr>
<td>14</td>
<td>LPOP</td>
<td>移出列表中地一个元素（与 BLPOP 的区别是不用设置阻塞时间）</td>
<td><code>LPOP list_key  1</code></td>
</tr>
<tr>
<td>15</td>
<td>LREM</td>
<td>指定一个或多个列表中相同元素进行删除</td>
<td><code>LREM list_key 1 &quot;sql&quot;</code></td>
</tr>
</tbody></table>
<h3 id="LTRIM"><a href="#LTRIM" class="headerlink" title="LTRIM"></a>LTRIM</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210720175635.png"><br>在 Redis 中 LTRIM 主要用于修剪（删除）已经存在的列表内的元素，其中分为 <code>start</code> 以及 <code>stop</code> 以 0 为开始，-1 可以表示列表里面的最后一个元素，-2 表倒数第二个 ……（这适用绝大多数依赖索引所完成的命令，如 <code>RANGE</code>）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 1000</span><br><span class="line">1) &quot;start&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;mongoDB&quot;</span><br><span class="line">5) &quot;sql&quot;</span><br><span class="line">6) &quot;mysql&quot;</span><br><span class="line">7) &quot;redislab.com&quot;</span><br><span class="line">8) &quot;redis&quot;</span><br><span class="line">9) &quot;world&quot;</span><br><span class="line">127.0.0.1:6379&gt; clear</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; LTRIM list_key -1 -1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 100</span><br><span class="line">1) &quot;world&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>要么从前删除要么从后删除，不可跨越索引</p>
</blockquote>
<p>我们所构造的 <code>-1~-1</code> 翻译到人可以理解的那就是，从倒数地一个开始，然后直到倒数第一个，也就是说之保留倒数地一个，当然你也可以通过 <code>LTRIM list_key -6 -1</code> 从倒数第六到最后一个来进行保留，删除其余外的元素：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LTRIM list_key -6 -1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 -1</span><br><span class="line">1) &quot;mongoDB&quot;</span><br><span class="line">2) &quot;sql&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;redislab.com&quot;</span><br><span class="line">5) &quot;redis&quot;</span><br><span class="line">6) &quot;world&quot;</span><br></pre></td></tr></table></figure>


<h3 id="BLPOP"><a href="#BLPOP" class="headerlink" title="BLPOP"></a>BLPOP</h3><p>主要的作用就是移出指定列表中的第一个元素，并返回所移出的元素名称，如果列表没有元素或没有该列表，则会等待超时时间过后即可关闭阻塞，或者得到发现可以移出的元素为止。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 -1</span><br><span class="line">1) &quot;world&quot;</span><br><span class="line">2) &quot;redis&quot;</span><br><span class="line">3) &quot;redislab.com&quot;</span><br><span class="line">4) &quot;mysql&quot;</span><br><span class="line">5) &quot;sql&quot;</span><br><span class="line">6) &quot;mongoDB&quot;</span><br><span class="line">7) &quot;one&quot;</span><br><span class="line">8) &quot;two&quot;</span><br><span class="line">9) &quot;start&quot;</span><br><span class="line">127.0.0.1:6379&gt; BLPOP list_key 0</span><br><span class="line">1) &quot;list_key&quot;</span><br><span class="line">2) &quot;world&quot;</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 -1</span><br><span class="line">1) &quot;redis&quot;</span><br><span class="line">2) &quot;redislab.com&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;sql&quot;</span><br><span class="line">5) &quot;mongoDB&quot;</span><br><span class="line">6) &quot;one&quot;</span><br><span class="line">7) &quot;two&quot;</span><br><span class="line">8) &quot;start&quot;</span><br></pre></td></tr></table></figure>

<h3 id="LTRIM-1"><a href="#LTRIM-1" class="headerlink" title="LTRIM"></a>LTRIM</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210720175619.png"><br>LTRIM 与列表中所有的移出命令不同的是，他可以指定一个或多个在列表中相同的元素进行删除。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; LPUSH list_key &quot;sql&quot; sql sql</span><br><span class="line">(integer) 6</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 -1</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;sql&quot;</span><br><span class="line">3) &quot;sql&quot;</span><br><span class="line">4) &quot;redislab.com&quot;</span><br><span class="line">5) &quot;mysql&quot;</span><br><span class="line">6) &quot;mongoDB&quot;</span><br><span class="line">127.0.0.1:6379&gt; LREM list_key 1 &quot;sql&quot;</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; LRANGE list_key 0 -1</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;sql&quot;</span><br><span class="line">3) &quot;redislab.com&quot;</span><br><span class="line">4) &quot;mysql&quot;</span><br><span class="line">5) &quot;mongoDB&quot;</span><br></pre></td></tr></table></figure>

<h2 id="集合（Set）"><a href="#集合（Set）" class="headerlink" title="集合（Set）"></a>集合（Set）</h2><p>集合（set）是一个字符串类型的无序集合，<strong>集合成员是唯一的</strong>，因此这意味着在集合中不可以有重复的成员数据，每个集合中最大可以存储40多亿个成员数据。通常可以通过 <code>SADD</code> 创建一个集合并向其添加成员（一个或多个），之后 <code>SMEMBERS</code>  来返回集合中的所有成员。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SADD set_key sql mysql redis mongoDB </span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS set_key</span><br><span class="line">1) &quot;mongoDB&quot;</span><br><span class="line">2) &quot;redis&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;sql&quot;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>SADD</td>
<td>创建集合并向其中添加一个或多个成员</td>
<td><code>SADD set_key sql mysql redis mongoDB</code></td>
</tr>
<tr>
<td>2</td>
<td>SINTERSTORE</td>
<td>将两个集合中相同的成员保存在另一个集合中</td>
<td><code>SINTERSTORE set_key set_one set_two</code></td>
</tr>
<tr>
<td>3</td>
<td>SDIFFSTORE</td>
<td>将两个集合中不相同的成员数据保存到另一个集合中</td>
<td><code>SDIFFSTORE set_key set_one set_two</code> （将 set_one 和 set_two 两个集合之间不相同的成员保存到 set_key 集合中）</td>
</tr>
<tr>
<td>4</td>
<td>SUNIONSTORE</td>
<td>将两个或多个集合之间的成员进行合并到另一个集合中</td>
<td><code>SUNIONSTORE key_set set_one set_two</code></td>
</tr>
<tr>
<td>5</td>
<td>SMOVE</td>
<td>将一个集合中的成员移动到另一个集合中</td>
<td><code>SMOVE set_one set_two &quot;sql&quot;</code> （将 set_one 集合中的成员“sql” 移动到 set_two 中）</td>
</tr>
<tr>
<td>6</td>
<td>SDIFF</td>
<td>返回指定集合中的不同成员</td>
<td><code>SDIFF set_two set_one</code></td>
</tr>
<tr>
<td>7</td>
<td>SINTER</td>
<td>返回指定集合中相同的成员</td>
<td><code>SINTER set_one set_two</code></td>
</tr>
<tr>
<td>8</td>
<td>SUNION</td>
<td>返回将指定集合合并后的并集</td>
<td><code>SUNION set_one set_two</code></td>
</tr>
<tr>
<td>9</td>
<td>SMEMBERS</td>
<td>返回指定集合中所有的成员</td>
<td><code>SMEMBERS set_key</code></td>
</tr>
<tr>
<td>10</td>
<td>SISMEMBER</td>
<td>判断集合中成员是否存在（存在返回1,不存在返回0）</td>
<td><code>SISMEMBER set_one &quot;mysql&quot;</code></td>
</tr>
<tr>
<td>11</td>
<td>SSCAN</td>
<td>遍历指定集合中所存在的键元素</td>
<td><code>SSCAN set_two 0 MATCH s*</code> （匹配该集合中所有以 “s” 开头的成员 ）</td>
</tr>
<tr>
<td>12</td>
<td>SRANDMEMBER</td>
<td>随机返回指定集合中的成员数（如果数大于成员数那么将返回所有成员）</td>
<td><code>SRANDMEMBER set_two  10</code></td>
</tr>
<tr>
<td>13</td>
<td>SPOP</td>
<td>根据指定数值随机删除集合成员，并返回所删除的成员数据</td>
<td><code>SPOP set_two 3</code></td>
</tr>
<tr>
<td>14</td>
<td>SREM</td>
<td>删除一个或多个集合中的成员</td>
<td><code>SREM set_two &quot;mysql&quot;</code></td>
</tr>
</tbody></table>
<h3 id="SINTERSTORE"><a href="#SINTERSTORE" class="headerlink" title="SINTERSTORE"></a>SINTERSTORE</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210721155306.png"><br>SINTERSTORE 命令在 Redis 中的主要作用就是将两个集合中相同的成员数据添加到另一个集合中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SMEMBERS set_one</span><br><span class="line">1) &quot;redis&quot;</span><br><span class="line">2) &quot;mysql&quot;</span><br><span class="line">3) &quot;sql&quot;</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS set_two</span><br><span class="line">1) &quot;mongoDB&quot;</span><br><span class="line">2) &quot;mysql&quot;</span><br><span class="line">3) &quot;redislab.com&quot;</span><br><span class="line">127.0.0.1:6379&gt; SINTERSTORE set_key set_one set_two</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS set_key</span><br><span class="line">1) &quot;mysql&quot;</span><br></pre></td></tr></table></figure>

<h3 id="SDIFF"><a href="#SDIFF" class="headerlink" title="SDIFF"></a>SDIFF</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210721155321.png"><br>返回两个集合中不相同的成员数据，相同的数据将不会被输出，按照官方的意思说这个命令主要返回地一个集合与其他集合之间的差异（说人话就是将其他集合不相同的数据进行输出）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SDIFF set_two set_one</span><br><span class="line">1) &quot;mongoDB&quot;</span><br><span class="line">2) &quot;redislab.com&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; SDIFF set_one set_two</span><br><span class="line">1) &quot;redis&quot;</span><br><span class="line">2) &quot;sql&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在集合中有两个非常重要的名词，分别是交集和差集，交集就是相同的意思，而差集就不相同的意思。</p>
</blockquote>
<h4 id="SDIFFSTORE"><a href="#SDIFFSTORE" class="headerlink" title="SDIFFSTORE"></a>SDIFFSTORE</h4><p>SDIFFSTORE 与 SDIFF 类似，但他主要的作用就是将两个集合之间的不相同数据（也就是差值）保存到另一个集合之中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SDIFFSTORE set_key set_one set_two</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS set_key</span><br><span class="line">1) &quot;redis&quot;</span><br><span class="line">2) &quot;sql&quot;</span><br></pre></td></tr></table></figure>

<h3 id="SINTER"><a href="#SINTER" class="headerlink" title="SINTER"></a>SINTER</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210721155335.png"><br>SINTER 与 SDIFF 不同之处在于，SINTER 用于返回所有集合中的交集，也就是相同的成员集合。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SINTER set_one set_two</span><br><span class="line">1) &quot;mysql&quot;</span><br></pre></td></tr></table></figure>

<h4 id="SINTERSTORE-1"><a href="#SINTERSTORE-1" class="headerlink" title="SINTERSTORE"></a>SINTERSTORE</h4><p>Redis 是一个考虑很全面的 key-value 数据库，因此他的命令也非常的具有针对性，该命令与 SDIFF 中的 SDIFFSTORE 非常相似，但该命令是将两个集合中的交集存储到另一个集合中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SINTERSTORE set_key set_one set_two</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS set_key</span><br><span class="line">1) &quot;mysql&quot;</span><br></pre></td></tr></table></figure>

<h3 id="SUNION"><a href="#SUNION" class="headerlink" title="SUNION"></a>SUNION</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210721155353.png"><br>SUNION 简单来说就是将两个集合并集，也就是将两个集合合并，将相同的数据所剔除，与 SDIFF 和 SINTER 一样，分为输出和存储两个非常具有针对性的命令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUNION set_one set_two</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;redis&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;mongoDB&quot;</span><br><span class="line">5) &quot;redislab.com&quot;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>所谓“并集” 也就是将两个或多个集合成员进行合并，如果不同集合之间的成员数据相同将会被剔除。</p>
</blockquote>
<h4 id="SUNIONSTORE"><a href="#SUNIONSTORE" class="headerlink" title="SUNIONSTORE"></a>SUNIONSTORE</h4><p>SUNIONSTORE 同样集成了 SUNION 命令逻辑，只不过是将输出改为了存储，将两个或多个集合之间的成员进行并集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SUNIONSTORE key_set set_one set_two</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; SMEMBERS key_set</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;redis&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;mongoDB&quot;</span><br><span class="line">5) &quot;redislab.com&quot;</span><br></pre></td></tr></table></figure>

<h2 id="有序集合（Zset）"><a href="#有序集合（Zset）" class="headerlink" title="有序集合（Zset）"></a>有序集合（Zset）</h2><p>有序集合（zset）和集合同样都是一个字符串类型的集合元素，他们都不允许同样重复的成员。不同的是他拥有一个双精度浮点数来达到从达到小排序的效果，与集合一样可以存储越 40亿个成员。</p>
<p>作为 Redis 几个最为主要的数据类型，他同样拥有针对性的命令，分别为 <code>ZADD</code> 即添加有序集合，他可以添加多个或单个（取决与你的习惯），当然也有 <code>ZRANGE</code> 来进行输出。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZADD key_zset 1 sql 2 mysql 3 mongoDB 4 redis</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;mysql&quot;</span><br><span class="line">4) &quot;2&quot;</span><br><span class="line">5) &quot;mongoDB&quot;</span><br><span class="line">6) &quot;3&quot;</span><br><span class="line">7) &quot;redis&quot;</span><br><span class="line">8) &quot;4&quot;</span><br></pre></td></tr></table></figure>


<h3 id="ZRANGE（从小到大）"><a href="#ZRANGE（从小到大）" class="headerlink" title="ZRANGE（从小到大）"></a>ZRANGE（从小到大）</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210721201140.png"><br>ZRANGE 命令会按照数值从小到大来进行排序（具有相同数值的成员将会被按照字典序列来进行排序）</p>
<blockquote>
<p>字典序列也就是根据 A、B、C、D 这个序列来进行从小到大来进行划分，也就是根据首字母开头进行排序。</p>
</blockquote>
<p>在通过 ZRANGE 命令进行查询的时候，如果不加上 <code>WITHSCORES</code> 返回的是一个元素列表，加上的话返回的则是一个数组列表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1</span><br><span class="line">1) &quot;sql&quot;</span><br><span class="line">2) &quot;mysql&quot;</span><br><span class="line">3) &quot;mongoDB&quot;</span><br><span class="line">4) &quot;redis&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZRANGEBYLEX"><a href="#ZRANGEBYLEX" class="headerlink" title="ZRANGEBYLEX"></a>ZRANGEBYLEX</h4><p>当集合中的元素都以相同的方式进行插入时，那么将会强制按照字典顺序来进行排列（在 Redis 中默认为英文字典 ABC以此类推进行排序）。</p>
<p>在这个命令中他支持有效的 start 以及 stop 修饰符，分别为 <code>[</code> 以及  <code>）</code> 和 <code>-</code> \ <code>+</code> 等。其中 <code>-/+</code> 分别表示最小和最大字符串，也就是开始和结尾，而 <code>[/(</code> 的区别是输出时是否包含元素 <code>[</code> 是包含 <code>(</code> 即不包含。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEBYLEX key_zset - +</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;b&quot;</span><br><span class="line">3) &quot;c&quot;</span><br><span class="line">4) &quot;d&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYLEX key_zset - (b</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYLEX key_zset - [b</span><br><span class="line">1) &quot;a&quot;</span><br><span class="line">2) &quot;b&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZRANGEBYSCORE"><a href="#ZRANGEBYSCORE" class="headerlink" title="ZRANGEBYSCORE"></a>ZRANGEBYSCORE</h4><p>ZRANGEBYSCORE 与 ZRANGEBYLEX 相似，但以我个人感觉更喜欢后者，前者的 <code>-inf</code> 和 <code>+inf</code> 与后者的 <code>-/+</code> 功能基本一样，区别是多了个 ”inf“，而之后的 <code>[</code> 和 <code>(</code> 功能也很一样，但将需要通过元素来作为参数改为了数值（在ZRANGEBYSCORE 中 <code>[</code> 并不支持）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE key_zset 1 2</span><br><span class="line">1) &quot;one&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE key_zset -inf 2</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE key_zset -inf (2</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGEBYSCORE key_zset -inf +inf</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZSCORE"><a href="#ZSCORE" class="headerlink" title="ZSCORE"></a>ZSCORE</h4><p>ZSCORE 命令是上述几个查询命令中最为朴素的命令之一，他主要根据成员名称来返回在其集合中的索引号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE zset_one 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;1&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;2&quot;</span><br><span class="line">7) &quot;three&quot;</span><br><span class="line">8) &quot;3&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZSCORE zset_one &quot;day&quot;</span><br><span class="line">&quot;0&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZCOUNT"><a href="#ZCOUNT" class="headerlink" title="ZCOUNT"></a>ZCOUNT</h4><p>ZCOUNT 同样支持 <code>(</code> 以及 <code>-inf\+inf</code>这类的表达式，他主要的作用就是计算出集合中的成员数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE zset_two 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br><span class="line">5) &quot;four&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZCOUNT zset_two -inf +inf</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; ZCOUNT zset_two -inf 3</span><br><span class="line">(integer) 4</span><br><span class="line">127.0.0.1:6379&gt; ZCOUNT zset_two -inf (3</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure>

<h3 id="ZREVRANK（从大到小）"><a href="#ZREVRANK（从大到小）" class="headerlink" title="ZREVRANK（从大到小）"></a>ZREVRANK（从大到小）</h3><p>ZREVRANK 同样是从大到小根据 0 为起始点进行排序，与 <code>ZREVEANGE</code> 类似，但该命令主要通过成员来返回在其集合中的索引。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE zset_one 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREVRANK zset_one &quot;day&quot;</span><br><span class="line">(integer) 3</span><br></pre></td></tr></table></figure>

<h4 id="ZREVRANGEBYSCORE"><a href="#ZREVRANGEBYSCORE" class="headerlink" title="ZREVRANGEBYSCORE"></a>ZREVRANGEBYSCORE</h4><p>ZREVRANGEBYSCORE 可以理解为是 <code>ZREVRANK</code> 的延续之作，他除了索引之外还支持 <code>ZRANGEBYLEX</code> 其中的表达式，除此之外还整合了 <code>ZRANGEBYSCORE</code> 来打通信息屏障，通过差异化和颗粒度达到引爆点来聚焦用户感知赛道。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZREVRANGEBYSCORE zset_one 4 1</span><br><span class="line">1) &quot;three&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREVRANGEBYSCORE zset_one 4 (1</span><br><span class="line">1) &quot;three&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREVRANGEBYSCORE zset_one +inf -inf</span><br><span class="line">1) &quot;three&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;day&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZREVEANGE"><a href="#ZREVEANGE" class="headerlink" title="ZREVEANGE"></a>ZREVEANGE</h4><p>ZREVRANGE 是一个更加纯粹的返回字典序列的一个命令，他比 ZRANGE 这群命令显得更加的纯粹和干练，同样是返回集合的作用，该命令只需要指定索引即可，不支持任何华丽胡少的表达式（但支持 redis 自带的）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZREVRANGE zset_one 0 -1</span><br><span class="line">1) &quot;three&quot;</span><br><span class="line">2) &quot;two&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;day&quot;</span><br></pre></td></tr></table></figure>

<h3 id="ZINCRBY"><a href="#ZINCRBY" class="headerlink" title="ZINCRBY"></a>ZINCRBY</h3><p>ZINCRBY 简单来讲就是对集合元素中的数组进行增加，假设集合中元素的数组为 0，那么即可通过 ZINCRBY 来进行增加：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZINCRBY key_zset 10 &quot;three&quot;</span><br><span class="line">&quot;13&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;1&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;2&quot;</span><br><span class="line">7) &quot;three&quot;</span><br><span class="line">8) &quot;13&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZINCRBY key_zset -10 &quot;three&quot;</span><br><span class="line">&quot;3&quot;</span><br></pre></td></tr></table></figure>

<h3 id="并集-x2F-合集"><a href="#并集-x2F-合集" class="headerlink" title="并集&#x2F;合集"></a>并集&#x2F;合集</h3><h4 id="ZINTERSTORE（合集）"><a href="#ZINTERSTORE（合集）" class="headerlink" title="ZINTERSTORE（合集）"></a>ZINTERSTORE（合集）</h4><p>将两个集合之间的交集存储到另一个集合中，需要指定两个集合中相同数的数值（也就是最终相同数所存储到另一个集合中的数量），默认情况下，结果集中的元素数值是这些集合中元素数值之和。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZINTERSTORE zset_key 2 zset_one zset_two</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE zset_key 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;2&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;4&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZUNIONSTORE-（并集）"><a href="#ZUNIONSTORE-（并集）" class="headerlink" title="ZUNIONSTORE （并集）"></a>ZUNIONSTORE （并集）</h4><p>ZUNIONSTORE 与 <code>ZINTERSTORE</code> 的区别就是一个是合集另一个是并集的一字之差，说简单一点就是将两个集合进行合并，相同的元素剔除。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE zset_two 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br><span class="line">5) &quot;four&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE zset_one 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZUNIONSTORE zset_key 2 zset_one zset_two</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE zset_key 0 -1 WITHSCORES</span><br><span class="line"> 1) &quot;day&quot;</span><br><span class="line"> 2) &quot;0&quot;</span><br><span class="line"> 3) &quot;one&quot;</span><br><span class="line"> 4) &quot;2&quot;</span><br><span class="line"> 5) &quot;four&quot;</span><br><span class="line"> 6) &quot;4&quot;</span><br><span class="line"> 7) &quot;two&quot;</span><br><span class="line"> 8) &quot;4&quot;</span><br><span class="line"> 9) &quot;three&quot;</span><br><span class="line">10) &quot;6&quot;</span><br></pre></td></tr></table></figure>

<p>但这样会造成集合中索引的相同，为了避免这类事情的发生我们可以自定义权重或和来解决 <code>ZUNIONSTORE zset_key 2 zset_one zest_two WEIGHTS 2 3 [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]</code>，这同样在 <code>ZINTERSTORE</code> 命令中适用。</p>
<h3 id="ZRANK"><a href="#ZRANK" class="headerlink" title="ZRANK"></a>ZRANK</h3><p>ZRANK 简单来说就单纯的是一个可以根据其集合成员来返回其索引的作用，如果其成员不存在则会返回 <code>nil</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANK zset_one &quot;day&quot;</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; ZRANK zset_one &quot;one&quot;</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE zset_one 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;1&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;2&quot;</span><br><span class="line">7) &quot;three&quot;</span><br><span class="line">8) &quot;3&quot;</span><br></pre></td></tr></table></figure>

<h3 id="ZREM"><a href="#ZREM" class="headerlink" title="ZREM"></a>ZREM</h3><p>ZREM 没有像后续几条命令一样那么否有诗书气自华，他主要根据成员来针对单个集合进行删除，在 Redis &#x3D;&gt; 2.4 版本中支持删除多个成员。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZADD key_zset 0 day 1 one 2 two 3 three 3 four</span><br><span class="line">(integer) 5</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;four&quot;</span><br><span class="line">5) &quot;three&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREM key_zset &quot;four&quot;</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;one&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;three&quot;</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>

<h4 id="ZREMRANGEBYLEX"><a href="#ZREMRANGEBYLEX" class="headerlink" title="ZREMRANGEBYLEX"></a>ZREMRANGEBYLEX</h4><p>该命令与 <code>ZREM</code> 相比起来就非常的丰富，他支持了一些较为简单的 Redis 表达式（<code>[</code> 包括自己），适合多个成员一起删除，当然你也可以选择删除单个（弊端就是你删除不了第一个和倒数第二个成员）。</p>
<p>但是 <code>ZREMRANGEBYLEX</code> 的弊端就是需要该集合索引都是一样的才可以进行删除。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line"> 1) &quot;day&quot;</span><br><span class="line"> 2) &quot;0&quot;</span><br><span class="line"> 3) &quot;four&quot;</span><br><span class="line"> 4) &quot;0&quot;</span><br><span class="line"> 5) &quot;one&quot;</span><br><span class="line"> 6) &quot;0&quot;</span><br><span class="line"> 7) &quot;three&quot;</span><br><span class="line"> 8) &quot;0&quot;</span><br><span class="line"> 9) &quot;two&quot;</span><br><span class="line">10) &quot;0&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREMRANGEBYLEX key_zset [day [one</span><br><span class="line">(integer) 3</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;three&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;0&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="ZREMRANGEBYRANK"><a href="#ZREMRANGEBYRANK" class="headerlink" title="ZREMRANGEBYRANK"></a>ZREMRANGEBYRANK</h4><p>该命令同样非产简约优雅，通过 <code>start\stop</code> 的操作可以快速删除多个集合中的成员，但劣势也一样展现出来，他并不能删除单个成员。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line"> 1) &quot;day&quot;</span><br><span class="line"> 2) &quot;0&quot;</span><br><span class="line"> 3) &quot;one&quot;</span><br><span class="line"> 4) &quot;1&quot;</span><br><span class="line"> 5) &quot;two&quot;</span><br><span class="line"> 6) &quot;2&quot;</span><br><span class="line"> 7) &quot;three&quot;</span><br><span class="line"> 8) &quot;3&quot;</span><br><span class="line"> 9) &quot;four&quot;</span><br><span class="line">10) &quot;5&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREMRANGEBYRANK key_zset 3 5</span><br><span class="line">(integer) 2</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;1&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;2&quot;</span><br></pre></td></tr></table></figure>

<h4 id="ZREMRANGEBYSCORE"><a href="#ZREMRANGEBYSCORE" class="headerlink" title="ZREMRANGEBYSCORE"></a>ZREMRANGEBYSCORE</h4><p>到 <code>ZREMRANGEBYSCORE</code> Reids 的有序列表删除命令就发展的非常特别且简单优雅，他同样适合于多个成员的删除操作，与前者不同的是到他这开始支持了 <code>-inf</code> 和 <code>（</code> (不包含该成员) 这类的表达式。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;day&quot;</span><br><span class="line">2) &quot;0&quot;</span><br><span class="line">3) &quot;one&quot;</span><br><span class="line">4) &quot;1&quot;</span><br><span class="line">5) &quot;two&quot;</span><br><span class="line">6) &quot;2&quot;</span><br><span class="line">127.0.0.1:6379&gt; ZREMRANGEBYSCORE key_zset -inf (1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; ZRANGE key_zset 0 -1 WITHSCORES</span><br><span class="line">1) &quot;one&quot;</span><br><span class="line">2) &quot;1&quot;</span><br><span class="line">3) &quot;two&quot;</span><br><span class="line">4) &quot;2&quot;</span><br></pre></td></tr></table></figure>
	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/redis/3.Redis 值/">Redis value</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/redis/" rel="tag">redis</a>
			</span>
		
	</div>

	

	
		<p>Redis 除了对键的操作，当然也有不少对值的操作，通常，就比如 <code>GETRANGE</code> 即截取一部分变量&#x2F;值信息，在 python 等语言中可以通过 <code>[key:n]</code> 来进行访问。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; GETRANGE key_name 1 4</span><br><span class="line">&quot;1234&quot;</span><br></pre></td></tr></table></figure>

<p>就如上述 code 中，<code>1</code> 是一个起始数，而 <code>4</code> 是一个结尾数，该键的值为 <code>0123456</code>，因此该命令可以实现出截取键值的效果。</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>GETRANGE</td>
<td>截取键值并返回</td>
<td><code>GETRANGE key_name start end</code></td>
</tr>
<tr>
<td>2</td>
<td>GETSET</td>
<td>重新设置键值的时候返回旧的键值数据</td>
<td><code>GETSET key_name &quot;Hello,world&quot;</code> （上一个 <code>key_name</code> 的值是 <code>0123456</code>，因此返回的也是他）</td>
</tr>
<tr>
<td>3</td>
<td>GETBIT</td>
<td>获取 key 所存储字符串的偏移量上的位（bit）</td>
<td><code>SETBIT value offset</code></td>
</tr>
<tr>
<td>4</td>
<td>SETRANGE</td>
<td>通过偏移量来修改 key 中的值</td>
<td><code>SETRANGE key_name 5 &quot; World!&quot;</code></td>
</tr>
<tr>
<td>5</td>
<td>SETBIT</td>
<td>修改 key 所存储的字符串上的偏移量 (bit)</td>
<td><code>SETBIT key_name 2 1</code></td>
</tr>
<tr>
<td>6</td>
<td>MGET</td>
<td>获取一个或多个 key</td>
<td><code> MGET key_name1 key_name2</code></td>
</tr>
<tr>
<td>7</td>
<td>MSET</td>
<td>设置多个 key（依然会通过新值替换旧值）</td>
<td><code>MSET key_one &quot;one&quot; key_two &quot;two&quot;</code></td>
</tr>
<tr>
<td>8</td>
<td>MSETNX</td>
<td>用于设置多个 key，遵循原子性操作（0失败，1成功）</td>
<td><code>MSETNX key_one &quot;one&quot; key_two &quot;two&quot;</code></td>
</tr>
<tr>
<td>9</td>
<td>SETNX</td>
<td>如果 key 存在则什么都不做，不存在则插入</td>
<td><code>SETNX key_name &quot;1&quot;</code> （如果 <code>key_name</code> 存在则返回 0，否则返回 1）</td>
</tr>
<tr>
<td>10</td>
<td>STRLEN</td>
<td>返回 key 值的字符串长度（如果存储的不是字符串类型则报错）</td>
<td><code>STRLEN key_name</code></td>
</tr>
<tr>
<td>11</td>
<td>APPEND</td>
<td>该命令的好处就是直接在原有的键值中直接拼合</td>
<td><code>APPEND key_one &quot;Hello&quot;</code> and <code>APPEND key_one &quot; World!&quot;</code> show <code>Hello World!</code></td>
</tr>
</tbody></table>
<h2 id="获取或存储偏移量上的位"><a href="#获取或存储偏移量上的位" class="headerlink" title="获取或存储偏移量上的位"></a>获取或存储偏移量上的位</h2><p>偏移量（Offset）简单概括就是存储地址和实际地址之间所存在的空段之间的距离，这通常被称之为有效地址或偏移量。</p>
<h3 id="GETSET"><a href="#GETSET" class="headerlink" title="GETSET"></a>GETSET</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210717221900.png"><br> 我们以 <code>GETSET</code> 命令为例，首先 <strong>H 的二进制数为：01001000</strong> ，通过 <code>GETSET</code> 分别输出一组后可以看到结果正是二进制数，因此本命令也就是获取 value 内的偏移量位数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; GETBIT key_name 0</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 1</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 2</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 3</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 4</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 5</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 6</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GETBIT key_name 7</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure>

<h3 id="SETBIT"><a href="#SETBIT" class="headerlink" title="SETBIT"></a>SETBIT</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210718011955.png"></p>
<p>.<code>SETBIT</code> 在 redis 中，主要用于更改 key 的存储偏移量，如 <code>SETBIT key_name 2 1</code> 则表示将从0，左到右开始计数，替换原有的位数从而替换为 <code>1</code>，让其从 <code>H</code> 改为 <code>h</code></p>
<p>.</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SETBIT key_name 2 1</span><br><span class="line">(integer) 0</span><br><span class="line">127.0.0.1:6379&gt; GET key_name</span><br><span class="line">&quot;hello,world&quot;</span><br></pre></td></tr></table></figure>

<h3 id="SETRANGE"><a href="#SETRANGE" class="headerlink" title="SETRANGE"></a>SETRANGE</h3><p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210718012004.png"></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SET key_name &quot;Hello&quot;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; SETRANGE key_name 5 &quot; World!&quot;</span><br><span class="line">(integer) 12</span><br><span class="line">127.0.0.1:6379&gt; GET key_name</span><br><span class="line">&quot;Hello World!&quot;</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>

<h2 id="自增与自减"><a href="#自增与自减" class="headerlink" title="自增与自减"></a>自增与自减</h2><table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>INCR</td>
<td>将数值自曾（key 不存在时为 0，假设运行100次 INCR 则 数值也会被自曾到 100，每运行一次数值 +1）</td>
<td><code>INCR key_one</code></td>
</tr>
<tr>
<td>2</td>
<td>INCRBY</td>
<td>在原有数值的基础上指定增加数值</td>
<td><code>INCRBY key_one 10</code>（假设 <code>key</code> 内值为2，则通过该命令增加 10，即12）</td>
</tr>
<tr>
<td>3</td>
<td>DECR</td>
<td>在原有数值基础上来进行值减</td>
<td><code>DECR key_one</code> （假设key内值为100，运行100次则为0）</td>
</tr>
<tr>
<td>4</td>
<td>DECRBY</td>
<td>在原有基础上自定义减值数</td>
<td><code>DECRBY key_one 9</code> (假设 key 值内为 10，则直接减为 9)</td>
</tr>
<tr>
<td>5</td>
<td>INCRBYFLOAT</td>
<td>为键的存储值中增加，可以执行像 <code>1.03e+08</code> 这样的科学计数法</td>
<td><code>INCRBYFLOAT key_name -0.01</code> \ <code>INCRBYFLOAT key_name 1.03e08</code></td>
</tr>
</tbody></table>
<h3 id="INCRBYFLOAT"><a href="#INCRBYFLOAT" class="headerlink" title="INCRBYFLOAT"></a>INCRBYFLOAT</h3><p>INCRBYFLOAT 的主要作用就是可以浮点数的增量以及支持诸如 <code>1.03E+08</code> 这样的科学计数法，此外无论加法计算所得到的精度实际长度有多长，该命令最终的结果只保留小数点后十七位数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SET key_name 1.04</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; INCRBYFLOAT key_name -0.01</span><br><span class="line">&quot;1.03&quot;</span><br><span class="line">127.0.0.1:6379&gt; INCRBYFLOAT key_name 1.03e08</span><br><span class="line">&quot;103000001.02999999999883585&quot;</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>

<blockquote>
<p>e 是一个科学计数法符号，通常以 “E” 表示，在科学计数法中为了公式的简便，可以将 1.03 x10的次方简写为 1.03E+08 的形式</p>
<blockquote>
<p>1.03 x 10的8次方，也就是 8个10相乘，之后在乘于 1.03，只保留十七位小数则应为 <code>103000001.02999999999883585</code></p>
</blockquote>
</blockquote>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/redis/2.Redis 键/">Redis Keys</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/redis/" rel="tag">redis</a>
			</span>
		
	</div>

	

	
		<p>键（keys）通常背后都会代表着一个数据结构，就已字符串的形式来称，他会表现为 <code>key_name=value_name</code> 在 Redis 中的命令与常见的数据传输码类似，如 <code>SET</code> 是创建、<code>GET</code> 是请求。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; SET key_name hello,world!</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; GET key_name</span><br><span class="line">&quot;hello,world!&quot;</span><br><span class="line">127.0.0.1:6379&gt; DEL key_name</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; GET key_name</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; </span><br></pre></td></tr></table></figure>

<p>在上面的命令中，我们通过 <code>SET</code> 创建了一个 <code>key_name</code>，他的值是 **hello,world!**，并通过 <code>GET</code> 进行请求，毫无疑问返回的是对应的值。</p>
<h2 id="键的操作"><a href="#键的操作" class="headerlink" title="键的操作"></a>键的操作</h2><p>在这个之间还使用到了 <code>DEL</code> 他是删除键的意思，而对于键的操作，并不只有这一条命令：</p>
<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>DEL</td>
<td>删除 Key</td>
<td><code>DEL value_name</code></td>
</tr>
<tr>
<td>2</td>
<td>DUMP</td>
<td>序列化 key，返回所序列化的值</td>
<td><code>DUMP key_name</code></td>
</tr>
<tr>
<td>3</td>
<td>EXISTS</td>
<td>检查 key 是否存在</td>
<td><code>EXISTS key_name</code> （存在返回1，不存在返回0，虽然你通过 <code>GET</code> 也可以媲美 <code>EXISTS</code> 的效果）</td>
</tr>
<tr>
<td>4</td>
<td>RANDOMKEY</td>
<td>随机从数据库中抽取一个 <code>key</code></td>
<td><code>RANDOMKEY</code></td>
</tr>
<tr>
<td>5</td>
<td>RENAME</td>
<td>修改 key 的名称</td>
<td><code> RENAME key_name new_name</code></td>
</tr>
<tr>
<td>6</td>
<td>RENAMENX</td>
<td>为了避免错误，虽然与 <code>RENAME</code> 同样是修改名称，但 <code>RENAME</code> 会直接覆盖（无论是否存在），而如果用此命令如果是相同的键名则会返回错误（0）创建成功会返回 1</td>
<td><code>RENAMENX key key_name</code></td>
</tr>
<tr>
<td>7</td>
<td>TYPE</td>
<td>返回 key 所存储的数据类型</td>
<td><code>TYPE key_name</code></td>
</tr>
</tbody></table>
<h3 id="易失-key"><a href="#易失-key" class="headerlink" title="易失 key"></a>易失 key</h3><table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
<th>Command</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>EXPIRE</td>
<td>设置 key 的过期时间</td>
<td><code>EXPIRE key_name 10</code>（&#96;&#96;&#96;EXPIRE 的单位是秒，即10秒后过期）</td>
</tr>
<tr>
<td>2</td>
<td>PEXPIRE</td>
<td>设置 key 的过期时间（毫秒）</td>
<td><code>PEXPIRE key_name 10</code></td>
</tr>
<tr>
<td>3</td>
<td>PSETEX</td>
<td>设置 key 的过期时间（毫秒）</td>
<td><code>PTTL key_one</code></td>
</tr>
<tr>
<td>4</td>
<td>EXPIREAT</td>
<td>通过 UNIX 时间戳的方式为 key 设置过期时间</td>
<td><code>EXPIREAT key_name 1626521040</code> （2021-07-17 19:24 过期）</td>
</tr>
<tr>
<td>5</td>
<td>PEXPIREAT</td>
<td>通过 Unix 时间戳的形式来设置 key 过期时间，与 <code>EXPIREAT</code> 的区别是他需要精确到毫秒</td>
<td><code>PEXPIREAT key_name 1626521962</code> （2021-07-17 19:39:22 过期）</td>
</tr>
<tr>
<td>6</td>
<td>PERSIST</td>
<td>移除 key 的过期时间，让其成为持久 key</td>
<td><code>PERSIST key_name</code></td>
</tr>
<tr>
<td>7</td>
<td>PTTL</td>
<td>以毫秒为单位返回 key 剩余的过期时间</td>
<td><code>PTTL key_name</code></td>
</tr>
<tr>
<td>8</td>
<td>TTL</td>
<td>以秒为单位返回 key 剩余的过期时间</td>
<td><code>TTL key_name</code></td>
</tr>
<tr>
<td>9</td>
<td>SETEX</td>
<td>同时设置过期时间为秒和键值</td>
<td><code>SETEX key_name 10 &quot;hello&quot;</code></td>
</tr>
</tbody></table>
<p>所谓的 <strong>易失 KEY</strong> 主要就是被 Redis 命令所设置了过期时间的（如<code>EXPIRE\EXPIRET\PEXPIRE\PEXPIREAT</code>）所进行设置的。</p>
<p>这些易失的KEY只能通过使用  <code>DEL、SET、GETSET、PERSIST</code> 等 STORE（存储） 命令进行清楚或覆盖成为 <strong>持久 key（persistent）</strong>。</p>
<blockquote>
<p>只能通过覆盖或清除的方式来让其成为持久key，像诸如更改 key 名称、修改 key 值、自增的做法并不适用，过期时间依然会移植到新的 key 上。</p>
<p>对于通过 <code>EXPIREAT</code> 命令来使用 Unix 时间戳让 key 成为易失 KEY 的方式，可以通过：<a target="_blank" rel="noopener" href="https://tool.chinaz.com/tools/unixtime.aspx">https://tool.chinaz.com/tools/unixtime.aspx</a> 转换工具来完成。</p>
<p>于此同时需要注意的是 <code>EXPIRE</code> 和 <code>SETEX</code> 相比之下 <code>SETEX</code> 区别就是原子性的操作</p>
<blockquote>
<p>原子性就是要么同时发生，要么就什么都不发生</p>
</blockquote>
</blockquote>
<h4 id="关于过期时间的准确性"><a href="#关于过期时间的准确性" class="headerlink" title="关于过期时间的准确性"></a>关于过期时间的准确性</h4><p>由于我们所使用的是 redis 2.6 因此过期时间的精度往往比 redis 2.4 提高到 0～1 毫秒之多。需要注意的是如果使用绝对 Unix 时间戳的方式进行存储，那么无论 Redis 是否运行都会流逝，但如果服务器时间并不精准，那也会导致易失 key 可靠性会降低。</p>
<h4 id="过期时间的淘汰流程"><a href="#过期时间的淘汰流程" class="headerlink" title="过期时间的淘汰流程"></a>过期时间的淘汰流程</h4><p>Redis key 的过期时间被分为两种淘汰过程，分别为被动方式和主动，而被动方式最好理解的就是当你访问了该 key ，而这时候恰好该 key 是过期的，那么这个 key 就会被发现之后淘汰了。</p>
<p>当然这种方式存在缺点，假设你这个 key 永远不会被访问，那么他岂不是会存在直到你访问的那天，于是 主动过期就出来了。</p>
<p>主动过期的淘汰方式也就是周期性的主动随机检查一部分被设置生存时间的 key，当扫到过期时间到了的 key 将会在 key 空间中删除，Redis 每 10 秒都会执行这个操作。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/redis/1.Redis 简介与安装/">Redis 安装与简介</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/redis/" rel="tag">redis</a>
			</span>
		
	</div>

	

	
		<p><img src="https://gitee.com/analysis-of-river-snow/drawing-bed/raw/master/20210717203722.png"></p>
<p>Redis 是一个遵循 BSD 协议，高性能且灵活的 key-value 数据结构存储，通常可以用于作为数据库、缓存和消息队列等应用，由于遵循的是 key-value 数据结构存储，他对比其他产品的特点在于：</p>
<ol>
<li>支持数据的持久话，可以将数据保存内存或者磁盘中，重启时可以可以加载到缓存或者内存中使用</li>
<li>支持简单的 key-value 类型数据的数据（同时提供了 list、set、zset、hash 结构存储）</li>
<li>高性能： redis 的一大特点，一个入门级的 Linux 服务器中可以每秒写入（SET）11w次，读取（GET）8.1w次，同时还支持 Pipeling 命令。</li>
<li>持久化：也就是说数据都存在内存中的时候，可以根据上次保存的到目前的时间来更新次数，以此他通过异步保存到磁盘上。</li>
<li>数据结构：Redis 所支持的数据结构有很多，除了常见的字符串、散列、集合、列表等还带有了数据集、位图、超级日志和担忧半径查询的地理空间索引等……</li>
<li>主&#x2F;从复制：Redis 分为 client&#x2F;server，主&#x2F;从复制只需要一行配置文件即可达成</li>
<li>生态支持：Redis 支持多个语言，如 Java、JavaScript（含 node.js）、Lua、Objective-C、PHP、Perl、R、Ruby、Scale、Go、C、C++、Python 等主流语言……</li>
</ol>
<h2 id="安装-Redis"><a href="#安装-Redis" class="headerlink" title="安装 Redis"></a>安装 Redis</h2><p>本文即主要介绍 Linux redis 的安装与启动，redis 的安装非常简单，需要通过下载在解压之后重新编译即可：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget http://download.redis.io/redis-stable.tar.gz</span><br><span class="line">tar -zxvf redis-6.0.8.tar.gz</span><br><span class="line">cd redis-6.0.8</span><br><span class="line">make</span><br></pre></td></tr></table></figure>

<p>之后编译完成即可通过通过 <code>cd src</code> 命令进入目录，来启动 redis-server&#x2F;client 客户端</p>
<blockquote>
<p>进入后先启动服务端在启动客户端</p>
<blockquote>
<p><code>./redis-server</code> 以及 <code>./redis-client</code>，当然这种启动的方式是使用默认配置文件的，如果你对服务也有调整即可使用制定的配置文件启动 <code>./redis-server ../redis.conf</code></p>
</blockquote>
</blockquote>
<p>当然既然有了服务端，那么你也可以将服务端在远程服务器启动，之后通过下述命令启动 redis-client：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h host -p port - a &quot;password&quot;</span><br></pre></td></tr></table></figure>

<p>当上述的命令执行完后，在客户端中输入 <code>PING</code> 来查看是否正常启动：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; PING</span><br><span class="line">PONG</span><br></pre></td></tr></table></figure>

<p>当返回的是 <code>PONG</code> 的时候即代表服务正常，如果所返回的是 <code>Could not connect to Redis at 127.0.0.1:6379: Connection refused</code> 将会代表服务端出现了问题或断开，这时请仔细检查服务端运行情况。</p>
<h2 id="配置-Redis"><a href="#配置-Redis" class="headerlink" title="配置 Redis"></a>配置 Redis</h2><p>在默认的情况下，Redis 是没有密码的，如果需要检测目前是否设置密码，需要通过 <code>CONFIG GET requirepass</code> 进行检测，如果属性为空，则可以通过下述命令来设置密码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; CONFIG SET requirepass &quot;toor&quot;</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; CONFIG GET requirepass</span><br><span class="line">1) &quot;requirepass&quot;</span><br><span class="line">2) &quot;toor&quot;</span><br></pre></td></tr></table></figure>

<p>这时候我们重新启动 redis-cli 后创建一个键，会返回 <code>(error) NOAUTH Authentication required.</code>，这将表示我们之前所整的操作已经被应用，只需要进行身份验证即可：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; AUTH &quot;toor&quot;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/hbase/2022-02-06-HBase API/">HBase API 使用</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/hbase/" rel="tag">hbase</a>
			</span>
		
	</div>

	

	
		<p>通常 HBase API 的使用是通过 <a target="_blank" rel="noopener" href="https://mvnrepository.com/artifact/org.apache.hbase/hbase-client">Apache HBase Client</a> 他主要提供了操作 HBase API 的一系列接口和类，新建 Maven 项目后引入依赖即可：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase-client --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0-alpha-2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hbase/hbase --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hbase<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hbase<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0-alpha-2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">type</span>&gt;</span>pom<span class="tag">&lt;/<span class="name">type</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Name</th>
<th>Info</th>
</tr>
</thead>
<tbody><tr>
<td>Admin</td>
<td>HBase 的管理 API。</td>
</tr>
<tr>
<td>Attributes</td>
<td></td>
</tr>
<tr>
<td>BufferedMutator</td>
<td>用于与类似于 Table 的单个 HBase 表进行通信，但用于批量异步放置。</td>
</tr>
<tr>
<td>BufferedMutator.ExceptionListener</td>
<td>侦听 BufferedMutator 上的异步异常。</td>
</tr>
<tr>
<td>Connection</td>
<td>一个集群连接，封装了与实际服务器的较低级别的单个连接以及与 zookeeper 的连接。</td>
</tr>
<tr>
<td>HConnection</td>
<td></td>
</tr>
<tr>
<td>HTableInterfaceFactory</td>
<td></td>
</tr>
<tr>
<td>RegionLocator</td>
<td>用于查看单个 HBase 表的区域位置信息。</td>
</tr>
<tr>
<td>ResultScanner</td>
<td>客户端扫描接口。</td>
</tr>
<tr>
<td>Row</td>
<td>一行</td>
</tr>
<tr>
<td>Table</td>
<td>一个表</td>
</tr>
</tbody></table>
<p>如果需要通过 API 操作 HBase 中的 CURD，那么就需要通过 HBase client 依赖中的 Admin 借口，创建后通过 Table 实例进行访问，以此向表中添加一行内容，Put 对象用于插入指定值、目标列以及时间戳等。</p>
<p>使用 put 提交更新后如果需要获取，那么可以通过 Get 实列进行查询，在特定的行中获取内容，亦或者使用 scan 设置一个扫描仪来返回结果，通常你也可以使用 Delete 来删除单元格或整个 row。</p>
<p>但在此之前你需要通过告诉配置对象你的客户端在那个地方连接，同工厂你可以将 hbase-site.xml 以及 core-site.xml 放在 Maven 项目文件中的 src&#x2F;main&#x2F;resources 文件夹内，此时 HbaseConfiguration 会自动帮你寻找。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.TableName;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Connection;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Get;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Table;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Result;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.ResultScanner;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Scan;</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">helloHbase</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span> <span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException &#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 自动检测 hbase-site.xml 和 core-site.xml 配置</span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">config</span> <span class="operator">=</span> HBaseConfiguration.create();</span><br><span class="line">            config.addResource(<span class="string">&quot;core-site.xml&quot;</span>);</span><br><span class="line">            config.addResource(<span class="string">&quot;hbase-site.xml&quot;</span>);</span><br><span class="line">            config.addResource(<span class="string">&quot;hdfs-site.xml&quot;</span>);</span><br><span class="line">            config.set(<span class="string">&quot;zookeeper.znode.parent&quot;</span>,<span class="string">&quot;/resources&quot;</span>);</span><br><span class="line">            config.set(<span class="string">&quot;hbase.zookeeper.property.clientPort&quot;</span>,<span class="string">&quot;2181&quot;</span>);</span><br><span class="line">            config.set(<span class="string">&quot;hbase.zookeeper.quorum&quot;</span>,<span class="string">&quot;192.168.115.10,192.168.115.11,192.168.115.12,192.168.115.13,192.168.115.14&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 创建一个链接，用于连接集群，之后关闭</span></span><br><span class="line">        <span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> ConnectionFactory.createConnection(config);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 实列化 Table 对象</span></span><br><span class="line">            <span class="type">Table</span> <span class="variable">table</span> <span class="operator">=</span> connection.getTable(TableName.valueOf(<span class="string">&quot;test&quot;</span>));</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="comment">// 通过 Put 构造函数添加一行</span></span><br><span class="line">                <span class="type">Put</span> <span class="variable">p</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Put</span>(Bytes.toBytes(<span class="string">&quot;row2&quot;</span>));</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 向该行插入一条信息</span></span><br><span class="line">                p.addColumn(Bytes.toBytes(<span class="string">&quot;myLittleFamily&quot;</span>), Bytes.toBytes(<span class="string">&quot;someQualifier&quot;</span>),</span><br><span class="line">                        Bytes.toBytes(<span class="string">&quot;Some Value&quot;</span>));</span><br><span class="line">                table.put(p);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 检索数据</span></span><br><span class="line">                <span class="type">Get</span> <span class="variable">g</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Get</span>(Bytes.toBytes(<span class="string">&quot;row2&quot;</span>));</span><br><span class="line">                <span class="type">Result</span> <span class="variable">r</span> <span class="operator">=</span> table.get(g);</span><br><span class="line">                <span class="type">byte</span> [] value = r.getValue(Bytes.toBytes(<span class="string">&quot;myLittleFamily&quot;</span>),</span><br><span class="line">                        Bytes.toBytes(<span class="string">&quot;someQualifier&quot;</span>));</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 返回 &quot;Some Value&quot;</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">valueStr</span> <span class="operator">=</span> Bytes.toString(value);</span><br><span class="line">                System.out.println(<span class="string">&quot;Get:&quot;</span> + valueStr);</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 使用 Scan 扫描</span></span><br><span class="line">                <span class="type">Scan</span> <span class="variable">s</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Scan</span>();</span><br><span class="line">                s.addColumn(Bytes.toBytes(<span class="string">&quot;myLittleFamily&quot;</span>),Bytes.toBytes(<span class="string">&quot;someQualifier&quot;</span>));</span><br><span class="line">                <span class="type">ResultScanner</span> <span class="variable">scanner</span> <span class="operator">=</span> table.getScanner(s);</span><br><span class="line"></span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    <span class="comment">// Scan 返回 Result 实列</span></span><br><span class="line">                    <span class="comment">// 对于迭代使用 while 循环打印</span></span><br><span class="line">                    <span class="keyword">for</span> (<span class="type">Result</span> <span class="variable">rr</span> <span class="operator">=</span> scanner.next(); rr != <span class="literal">null</span>; rr = scanner.next()) &#123;</span><br><span class="line">                        System.out.println(<span class="string">&quot;Found row: &quot;</span> + rr);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    <span class="comment">// 完成后关闭 Scan 进程</span></span><br><span class="line">                    scanner.close();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                <span class="comment">// 关闭表和集群的连接</span></span><br><span class="line">                <span class="keyword">if</span> (table != <span class="literal">null</span>) table.close();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">             connection.close();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>ERROR</th>
</tr>
</thead>
<tbody><tr>
<td><a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/71028364/java-api-operate-hbase-api-error-connecting-to-cluster-exception-making-rpc-to">https://stackoverflow.com/questions/71028364/java-api-operate-hbase-api-error-connecting-to-cluster-exception-making-rpc-to</a></td>
</tr>
<tr>
<td></td>
</tr>
</tbody></table>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/hbase/2021-12-06-HBase Command/">HBase 基础语法</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/hbase/" rel="tag">hbase</a>
			</span>
		
	</div>

	

	
		<h2 id="CURD"><a href="#CURD" class="headerlink" title="CURD"></a>CURD</h2><h3 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h3><h4 id="Create-and-Table-of-Coumn-familu-or-Column"><a href="#Create-and-Table-of-Coumn-familu-or-Column" class="headerlink" title="Create and Table of Coumn familu or Column"></a>Create and Table of Coumn familu or Column</h4><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/3.hbase%20%E5%9F%BA%E7%A1%80%E8%AF%AD%E6%B3%95.md/509553510229673.png"><br>Hbase 的表都是由列和族（Column Family）所组成的，列是列族的子项，而每个列或多个列会形成一行(row)。在 HBase 中可以使用 <code>create</code> 创建一个表。</p>
<blockquote>
<p>在创建的途中可能会遇到 Hadoop 集群的报错: “util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable” 来导致最终 <code>create</code> 语法无法成功插入的报错，此问题的解决就是清除 Hadoop 除去 myid 和 version 相关的集群数据目录，然后重启并格式化即可，在重新启动下 Hbase 集群即可。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">create</span> <span class="string">&#x27;test&#x27;</span>, <span class="string">&#x27;cf&#x27;</span></span><br><span class="line">Created <span class="keyword">table</span> test</span><br><span class="line">Took <span class="number">11.8491</span> seconds</span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> Hbase::<span class="keyword">Table</span> <span class="operator">-</span> test</span><br></pre></td></tr></table></figure>

<p>通过 <code>create</code> 所创建的，一个是表(table)，另一个则是列族(column family)，而列(Column)定义是在插入第一条数据的时候才会创建，也就是单元格(call)。所创建的所有数据都定义在列族上，而表的本身则是存放列族和列。</p>
<h4 id="Create-Table-of-Column-family"><a href="#Create-Table-of-Column-family" class="headerlink" title="Create Table of Column family"></a>Create Table of Column family</h4><p>通过 <code>describe &#39;table&#39;</code>  可以看之前所创建的 <code>cf</code> 列族，而实际上 <code>describe</code> 大部分都是列族的属性，这体现在 <code>alter &#39;text&#39;, &#39;cf2&#39;</code> 中：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">describe &#x27;test&#x27;</span><br><span class="line">Table test is ENABLED</span><br><span class="line">test</span><br><span class="line">COLUMN FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME =&gt; &#x27;cf&#x27;, BLOOMFILTER =&gt; &#x27;ROW&#x27;, IN_MEMORY =&gt; &#x27;false&#x27;, VERSIONS =&gt; &#x27;1&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, COMPRESSION =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, BLOCKCACHE =&gt; &#x27;true&#x27;, BLOCKSIZE =&gt; &#x27;65536&#x27;, REPLICATION_SCOPE =&gt; &#x27;0&#x27;&#125;</span><br><span class="line"></span><br><span class="line">&#123;NAME =&gt; &#x27;cf2&#x27;, BLOOMFILTER =&gt; &#x27;ROW&#x27;, IN_MEMORY =&gt; &#x27;false&#x27;, VERSIONS =&gt; &#x27;1&#x27;, KEEP_DELETED_CELLS =&gt; &#x27;FALSE&#x27;, DATA_BLOCK_ENCODING =&gt; &#x27;NONE&#x27;, COMPRESSION =&gt; &#x27;NONE&#x27;, TTL =&gt; &#x27;FOREVER&#x27;, MIN_VERSIONS =&gt; &#x27;0&#x27;, BLOCKCACHE =&gt; &#x27;true&#x27;, BLOCKSIZE =&gt; &#x27;65536&#x27;, REPLICATION_SCOPE =&gt; &#x27;0&#x27;&#125;</span><br><span class="line"></span><br><span class="line">2 row(s)</span><br><span class="line">Quota is disabled</span><br><span class="line">Took 0.0608 seconds</span><br></pre></td></tr></table></figure>

<p>可以看出 describe 所列出的表属性大多数都是根据列族而进行输出的，涉及到表的属性很少。</p>
<h4 id="Put"><a href="#Put" class="headerlink" title="Put"></a>Put</h4><p>Hbase 的插入数据也体现在出了高离散的特点，其格式也是 <strong>表, 行, 列族:列名, 数据值</strong>，也就是必须指定数据值要插入到那一行，那一列当中，对应的命令是: <code>put &#39;test&#39;, &#39;row1&#39;, &#39;cf:name&#39;, &#39;hello,world!&#39;</code>，即使用 <code>put</code> 向 test 表中的第一行，列族为 cf 插入了列明为 name 的 hello,world 数据值。之后通过 <code>scan &#39;test&#39;</code> 可扫描出：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> scan <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"> row1                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">14</span>:<span class="number">24.144</span>, <span class="keyword">value</span><span class="operator">=</span>hello,world<span class="operator">!</span></span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.2802</span> seconds</span><br></pre></td></tr></table></figure>

<p>通过 <code>scan</code> 可以扫描出该表的所有数据，可以看出对照关系是：</p>
<table>
<thead>
<tr>
<th>ROW</th>
<th>COLUMN+CELL</th>
</tr>
</thead>
<tbody><tr>
<td>rowkey</td>
<td>column&#x3D;列族:列名, timestamp&#x3D;时间戳, value&#x3D;数据值</td>
</tr>
</tbody></table>
<p>值得注意的是单元格可以通过 timestamp 来多个版本的值，通俗来点的说他也起到了版本号(version)的作用，而 HBase 会取版本号最大的数据版本进行输出，但同时在默认情况下 timestamp 是由系统自动生成的，当然我们也可以自行定义时间戳。</p>
<p>在自定义时间戳之前我们需要通过 <code>alter &#39;test&#39;,&#123;NAME=&gt;&#39;cf&#39;,VERSIONS=&gt;5&#125;</code> 来修改版本数。</p>
<blockquote>
<p>这样一来就算在一个单元格无论修改多少次，HBase 也会保存最后一个版本，如：</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row2,&#x27;</span>cf:name<span class="string">&#x27;,&#x27;</span>date_time<span class="string">&#x27;,1638909613</span></span><br><span class="line"><span class="string">put &#x27;</span>test<span class="string">&#x27;, &#x27;</span>row2<span class="string">&#x27;, &#x27;</span>cf:name<span class="string">&#x27;,&#x27;</span>date_update<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>

<p>那么通过 <code>scan</code> 的方式肯定会现实时间戳最高的一位进行输出，也就是 date_update，这是因为 date_time 的时间戳转换后是 1970-01-20T08:00:45.613 而，date_update 的时间戳是 2021-12-07T20:40:52.334，所以没有输出 date_time</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0128 seconds</span><br></pre></td></tr></table></figure>

<p>不过我们如果真的需要查询 date_time 的话，可以通过 get 的表达式来获取单元格的数据，也就是 <code>get &#39;test&#39;,&#39;row2&#39;,&#123;COLUMN=&gt;&#39;cf:name&#39;, VERSIONS=&gt;3&#125;</code></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">get</span> <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row2&#x27;</span>,&#123;<span class="keyword">COLUMN</span><span class="operator">=</span><span class="operator">&gt;</span><span class="string">&#x27;cf:name&#x27;</span>, VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">3</span>&#125;</span><br><span class="line"><span class="keyword">COLUMN</span>                          CELL</span><br><span class="line"> cf:name                        <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">40</span>:<span class="number">52.334</span>, <span class="keyword">value</span><span class="operator">=</span>date_update</span><br><span class="line"> cf:name                        <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-20</span>T08:<span class="number">00</span>:<span class="number">45.613</span>, <span class="keyword">value</span><span class="operator">=</span>data_timestamp</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br></pre></td></tr></table></figure>

<p>对于上述这种表达式，同样的 scan 以及大部分的 hbase 语法都支持，比如我们可以通过 scan 起始行(STARTROW)和结束行(ENDROW)的表达式来进行筛选：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;,&#123;STARTROW=&gt;&#x27;row1&#x27;,ENDROW=&gt;&#x27;row2&#x27;&#125;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0793 seconds</span><br></pre></td></tr></table></figure>

<p>同样的基于这种表达式，也赋予了和 Put 一教高下的能力，比如同样的可以使用表达式来查询出多个单元块的版本数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;,&#123;VERSIONS=&gt;5&#125;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line"> row2                           column=cf:name, timestamp=1970-01-20T08:00:45.613, value=data_timestamp</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0773 seconds</span><br></pre></td></tr></table></figure>

<h3 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h3><h4 id="list"><a href="#list" class="headerlink" title="list"></a>list</h4><p>通过 <code>list</code> 或 <code>list &lt;table_name&gt;</code> 的方式来查询当前库中有多少个表以及查询单个表，列出刚刚所创建的表是否存在</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">list <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="keyword">TABLE</span></span><br><span class="line">test</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.3364</span> seconds</span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> [&quot;test&quot;]</span><br></pre></td></tr></table></figure>

<h4 id="describe"><a href="#describe" class="headerlink" title="describe"></a>describe</h4><p>查看表和列族的详细信息，实际上有很大一部分的信息输出都是针对列族的，主要的原因是 HBase 中的表上只有几个属性，大部分的属性都在列族上而已。</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">describe</span> <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="keyword">Table</span> test <span class="keyword">is</span> ENABLED</span><br><span class="line">test</span><br><span class="line"><span class="keyword">COLUMN</span> FAMILIES DESCRIPTION</span><br><span class="line">&#123;NAME <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;cf&#x27;</span>, BLOOMFILTER <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;ROW&#x27;</span>, IN_MEMORY <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;false&#x27;</span>, VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;1&#x27;</span>, KEEP_DELETED_CELLS <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;FALSE&#x27;</span>, DATA_BLOCK_ENCODING <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;NONE&#x27;</span>, COMPRESSION <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;NONE&#x27;</span>, TTL <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;FOREVER&#x27;</span>, MIN_VERSIONS <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;0&#x27;</span>, BLOCKCACHE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;true&#x27;</span>, BLOCKSIZE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;65536&#x27;</span>, REPLICAT</span><br><span class="line">ION_SCOPE <span class="operator">=</span><span class="operator">&gt;</span> <span class="string">&#x27;0&#x27;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Quota <span class="keyword">is</span> disabled</span><br><span class="line">Took <span class="number">2.1830</span> seconds</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Name</th>
<th>Name_cn</th>
<th>Info</th>
</tr>
</thead>
<tbody><tr>
<td>NAME</td>
<td>Name family 名</td>
<td>Name_family 的名</td>
</tr>
<tr>
<td>BLOOMFILTER</td>
<td>布隆过滤</td>
<td>在 1970 年由 Burton Howard Bloom 所提出，用于测试一个元素是否在特定集中。</td>
</tr>
<tr>
<td></td>
<td></td>
<td>ROW 提高随机读取性能</td>
</tr>
<tr>
<td>IN_MEMORY</td>
<td>是否在内存中</td>
<td>HBase 所提供的缓存选择，默认为 “false”</td>
</tr>
<tr>
<td>VERSIONS</td>
<td>版本数</td>
<td>记录单元格所插入的数据，只保留最后一个版本并记录所有版本的数据</td>
</tr>
<tr>
<td>KEEP_DELETED_CELLS</td>
<td>删除标记</td>
<td>是否保留已经删除的单元格，默认为 “false”</td>
</tr>
<tr>
<td>DATA_BLOCK_ENCODING</td>
<td>数据块编码</td>
<td>数据块编码，可自行进行选择，默认 “none”</td>
</tr>
<tr>
<td>COMPRESSION</td>
<td>压缩算法</td>
<td>决定是否启用压缩算法，默认 “none”</td>
</tr>
<tr>
<td>TTL</td>
<td>生存时间</td>
<td>制定后可以达到过期事件后自动删除行，默认为 “FOREVER”</td>
</tr>
<tr>
<td>MIN_VERSIONS</td>
<td>最小版本</td>
<td>存储列中的最小版本号，默认为 “0”，也意味着该功能处于禁用状态</td>
</tr>
<tr>
<td>BLOCKCACHE</td>
<td>块缓存</td>
<td>Hbase 提供了 LruBlockCache 和 BucketCache 两种缓存机制,通常是 off-heap</td>
</tr>
<tr>
<td>BLOCKSIZE</td>
<td>块大小</td>
<td>HDFS 块，单元格越带，块大小就越大，默认值为 64k</td>
</tr>
<tr>
<td>REPLICATION_SCOPE</td>
<td>复制范围</td>
<td>允许使用源集群预写日志来传播更改，使一个集群的状态与零一个集群的状态保持同步</td>
</tr>
</tbody></table>
<h4 id="scan"><a href="#scan" class="headerlink" title="scan"></a>scan</h4><p>通过 <code>scan</code> 可以扫描出该表的所有数据，可以看出对照关系是：</p>
<table>
<thead>
<tr>
<th>ROW</th>
<th>COLUMN+CELL</th>
</tr>
</thead>
<tbody><tr>
<td>rowkey</td>
<td>column&#x3D;列族:列名, timestamp&#x3D;时间戳, value&#x3D;数据值</td>
</tr>
</tbody></table>
<p>值得注意的是单元格可以通过 timestamp 来多个版本的值，通俗来点的说他也起到了版本号(version)的作用，而 HBase 会取版本号最大的数据版本进行输出，但同时在默认情况下 timestamp 是由系统自动生成的，当然我们也可以自行定义时间戳。</p>
<p>在自定义时间戳之前我们需要通过 <code>alter &#39;test&#39;,&#123;NAME=&gt;&#39;cf&#39;,VERSIONS=&gt;5&#125;</code> 来修改版本数。</p>
<blockquote>
<p>这样一来就算在一个单元格无论修改多少次，HBase 也会保存最后一个版本，如：</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">put <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row2,&#x27;</span>cf:name<span class="string">&#x27;,&#x27;</span>date_time<span class="string">&#x27;,1638909613</span></span><br><span class="line"><span class="string">put &#x27;</span>test<span class="string">&#x27;, &#x27;</span>row2<span class="string">&#x27;, &#x27;</span>cf:name<span class="string">&#x27;,&#x27;</span>date_update<span class="string">&#x27;</span></span><br></pre></td></tr></table></figure>

<p>那么通过 <code>scan</code> 的方式肯定会现实时间戳最高的一位进行输出，也就是 date_update，这是因为 date_time 的时间戳转换后是 1970-01-20T08:00:45.613 而，date_update 的时间戳是 2021-12-07T20:40:52.334，所以没有输出 date_time</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0128 seconds</span><br></pre></td></tr></table></figure>

<p>基于表达式的应用，也赋予了和 Put 一教高下的能力，比如同样的可以使用表达式来查询出多个单元块的版本数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scan &#x27;test&#x27;,&#123;VERSIONS=&gt;5&#125;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line"> row2                           column=cf:name, timestamp=1970-01-20T08:00:45.613, value=data_timestamp</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0773 seconds</span><br></pre></td></tr></table></figure>

<h3 id="Delete"><a href="#Delete" class="headerlink" title="Delete"></a>Delete</h3><h4 id="Delete-of-data-and-tombstone-marker"><a href="#Delete-of-data-and-tombstone-marker" class="headerlink" title="Delete of data and tombstone marker"></a>Delete of data and tombstone marker</h4><p>Delete 其如其名就是删除，同样的根据高离散的格式来定义表达式，如 <code>delete &#39;test&#39;,&#39;row1&#39;,&#39;cf:name&#39;</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&gt; scan &#x27;test&#x27;,&#123;VERSIONS=&gt;5&#125;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row1                           column=cf:name, timestamp=2021-12-07T20:14:24.144, value=hello,world!</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line"> row2                           column=cf:name, timestamp=1970-01-20T08:00:45.613, value=data_timestamp</span><br><span class="line">2 row(s)</span><br><span class="line">Took 0.0181 seconds</span><br><span class="line"></span><br><span class="line">&gt; delete &#x27;test&#x27;,&#x27;row1&#x27;,&#x27;cf:name&#x27;</span><br><span class="line">Took 0.0246 seconds</span><br><span class="line"></span><br><span class="line">&gt; scan &#x27;test&#x27;,&#123;VERSIONS=&gt;5&#125;</span><br><span class="line">ROW                             COLUMN+CELL</span><br><span class="line"> row2                           column=cf:name, timestamp=2021-12-07T20:40:52.334, value=date_update</span><br><span class="line"> row2                           column=cf:name, timestamp=1970-01-20T08:00:45.613, value=data_timestamp</span><br><span class="line">1 row(s)</span><br><span class="line">Took 0.0080 seconds</span><br></pre></td></tr></table></figure>

<p>而这个时候就会牵扯到版本记录，如我们将 row2 的时间戳 1641645000 删除，则可以构造表达式 <code>delete &#39;test&#39;,&#39;row2&#39;,&#39;cf:name&#39;,1670445613</code></p>
<blockquote>
<p>很多时候 Hbase 的时间戳转换的格式为 <code>yyyy-MM-dd&#39;T&#39;HH:mm:ss.SSS</code>，我们可以直接在 hbase shell 中来进行转换：</p>
<ol>
<li>import java.text.SimpleDateFormat</li>
<li>import java.text.ParsePosition</li>
<li>SimpleDateFormat.new(“yyyy-MM-dd’T’HH:mm:ss.SSS”).parse(“1970-01-20T08:00:45.613”,ParsePosition.new(0<br>)).getTime()</li>
</ol>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> scan <span class="string">&#x27;test&#x27;</span>,&#123;VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">5</span>&#125;</span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">40</span>:<span class="number">52.334</span>, <span class="keyword">value</span><span class="operator">=</span>date_update</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.0449</span> seconds</span><br></pre></td></tr></table></figure>

<p>上述提到的墓碑标记(tombstone marker) 即被删除的数据，他并不是被真正的删除而是被打上了一个墓碑标记，打上后会连同之前的版本也会被标记为不可见。</p>
<p>同时为了性能着想他并不会马上清除，而是定期的去清理这些已经被删除的记录，而所谓的定期则是在 HBase 做自动合并的时候将墓碑合并到一起进行删除，以此来将 HBase 的消耗降到最低，我们可以通过 <code>scan &#39;test&#39;,&#123;RAW=&gt;true,VERSIONS=&gt;5&#125;</code> 来进行查看被打赏墓碑标记的数据 ：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> scan <span class="string">&#x27;test&#x27;</span>,&#123;RAW<span class="operator">=</span><span class="operator">&gt;</span><span class="literal">true</span>,VERSIONS<span class="operator">=</span><span class="operator">&gt;</span><span class="number">5</span>&#125;</span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"> row1                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">14</span>:<span class="number">24.144</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row1                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">14</span>:<span class="number">24.144</span>, <span class="keyword">value</span><span class="operator">=</span>hello,world<span class="operator">!</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">40</span>:<span class="number">52.334</span>, <span class="keyword">value</span><span class="operator">=</span>date_update</span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-20</span>T08:<span class="number">00</span>:<span class="number">45.613</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-20</span>T08:<span class="number">00</span>:<span class="number">45.613</span>, <span class="keyword">value</span><span class="operator">=</span>data_timestamp</span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-20</span>T00:<span class="number">00</span>:<span class="number">45</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-19</span>T23:<span class="number">15</span>:<span class="number">09.613</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-19</span>T23:<span class="number">14</span>:<span class="number">40.852</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-01</span>T00:<span class="number">27</span>:<span class="number">21.645</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">1970</span><span class="number">-01</span><span class="number">-01</span>T00:<span class="number">27</span>:<span class="number">18.911</span>, type<span class="operator">=</span><span class="keyword">Delete</span></span><br><span class="line"><span class="number">2</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.0579</span> seconds</span><br></pre></td></tr></table></figure>

<h4 id="deleteall"><a href="#deleteall" class="headerlink" title="deleteall"></a>deleteall</h4><p>deteall 与单纯的 detell 的区别是他是删除整行目录的，也就是说他无需指定列族，指定到 rowkey 即可进行删除该 rowkey 下的数据：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="operator">&gt;</span> scan <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"> row2                           <span class="keyword">column</span><span class="operator">=</span>cf:name, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-12</span><span class="number">-07</span>T20:<span class="number">40</span>:<span class="number">52.334</span>, <span class="keyword">value</span><span class="operator">=</span>date_update</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.1310</span> seconds</span><br><span class="line"></span><br><span class="line"><span class="operator">&gt;</span> deleteall <span class="string">&#x27;test&#x27;</span>,<span class="string">&#x27;row2&#x27;</span></span><br><span class="line">Took <span class="number">0.0148</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">062</span>:<span class="number">0</span><span class="operator">&gt;</span> scan <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"><span class="number">0</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.0095</span> seconds</span><br></pre></td></tr></table></figure>

<h4 id="disable"><a href="#disable" class="headerlink" title="disable"></a>disable</h4><p>disable 的命令作用是停用表，也就是更加真实应对分布式数据库高并发高和高性能下所提供的一个命令，<strong>在删除  HBase 表的时候强烈建议西安 disable 在 drop 删除表。</strong></p>
<blockquote>
<p>如果 disable 目标表下线的时候很快则表明这个表的依赖度不高，但如果假设依赖度很高的话则会很慢，因为他会通知所有 RegisionServer 来下线该表，以保证完全不参与任何工作了在进行下线。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">063</span>:<span class="number">0</span><span class="operator">&gt;</span> disable <span class="string">&#x27;test&#x27;</span></span><br><span class="line">Took <span class="number">15.3142</span> seconds</span><br><span class="line">hbase(main):<span class="number">064</span>:<span class="number">0</span><span class="operator">&gt;</span> scan <span class="string">&#x27;test&#x27;</span></span><br><span class="line"><span class="type">ROW</span>                             <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line">org.apache.hadoop.hbase.TableNotEnabledException: test <span class="keyword">is</span> disabled.</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.ConnectionImplementation.relocateRegion(ConnectionImplementation.java:<span class="number">770</span>)</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.RpcRetryingCallerWithReadReplicas.getRegionLocations(RpcRetryingCallerWithReadReplicas.java:<span class="number">330</span>)</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.ScannerCallable.prepare(ScannerCallable.java:<span class="number">139</span>)</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.ScannerCallableWithReplicas$RetryingRPC.prepare(ScannerCallableWithReplicas.java:<span class="number">408</span>)</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.RpcRetryingCallerImpl.callWithRetries(RpcRetryingCallerImpl.java:<span class="number">105</span>)</span><br><span class="line">        <span class="keyword">at</span> org.apache.hadoop.hbase.client.ResultBoundedCompletionService$QueueingFuture.run(ResultBoundedCompletionService.java:<span class="number">80</span>)</span><br><span class="line">        <span class="keyword">at</span> java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:<span class="number">1149</span>)</span><br><span class="line">        <span class="keyword">at</span> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:<span class="number">624</span>)</span><br><span class="line">        <span class="keyword">at</span> java.lang.Thread.run(Thread.java:<span class="number">748</span>)</span><br><span class="line"></span><br><span class="line">ERROR: <span class="keyword">Table</span> test <span class="keyword">is</span> disabled<span class="operator">!</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">For</span> usage try <span class="string">&#x27;help &quot;scan&quot;&#x27;</span></span><br></pre></td></tr></table></figure>

<p>当该表下线后则无法使用 <code>scan</code> 命令进行查询，并会输出错误信息，来表示当前表已经被关闭，无法 scan。</p>
<h4 id="drop"><a href="#drop" class="headerlink" title="drop"></a>drop</h4><p>当使用 disable 停用表后，则开始基于 drop 进行删除表，在此之前我们使用 <code>list</code> 还是可以发现 <code>test</code> 表存在的，但如果使用 <code>drop &#39;test&#39;</code> 后，则真的无法使用 <code>list</code> 查看到 test 表的任何痕迹了。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/hbase/2021-11-22-HBase and distributed outline/">HBase 与分布式数据库概述</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/hbase/" rel="tag">hbase</a>
			</span>
		
	</div>

	

	
		<p>分布式数据库系统（Distributed Database System, DDBS），研究开始于 20实际70年代中期。随着数据库应用需求的扩展和信息技术特别是计算机网络与数字通信技术的飞速发展，集中式的单体数据库系统已经无法适应这样的环境。</p>
<h2 id="DDBS-起源"><a href="#DDBS-起源" class="headerlink" title="DDBS 起源"></a>DDBS 起源</h2><h3 id="集中式数据库痛点"><a href="#集中式数据库痛点" class="headerlink" title="集中式数据库痛点"></a>集中式数据库痛点</h3><ol>
<li><p>对于集中式数据库，主要的不足体现在数据按照需要在网络上分布存储，假设采用集中式处理，将会造成附加成本和通信的开销。</p>
</li>
<li><p>应用集中在一台计算机或服务器中运行，一旦发生故障将会导致整个系统的运行，可靠性受到威胁。</p>
</li>
<li><p>集中式的处理导致系统规模和配置不够灵活，可扩展性较差，这种情况下数据库应用普遍构建于网络上。</p>
</li>
</ol>
<blockquote>
<p>在 2004 年左右或之前，英国国家计算机中心(United Kingodom National Computing Centre, UK-NCC) 专门对分布式数据库进行了分析和预测，并表明：“在未来 10 年后计算机科学发展的主要方向之一”。</p>
<p>在 2021 年的今天很明显证实了这一点</p>
</blockquote>
<h3 id="信息孤岛-Information-Island"><a href="#信息孤岛-Information-Island" class="headerlink" title="信息孤岛 (Information Island)"></a>信息孤岛 (Information Island)</h3><p>例如大型互联网公司、政府机关等单位中，这些组织内都有一个自己所维护的数据库，比如开发部门(bj-dev)，行政部门(sz-adm)，这些数据库通常是已经分布的了。</p>
<p>在这种情况下，企业的整个信息资源就被分割成了信息孤岛，而分布式数据库的主要作用就是将信息孤岛连接起来。</p>
<p>做个比较明显的比喻就是分布式系统可以明显的体现出组织的系统架构，本地是数据本地保存或维护，同时也可以在需要时存取异地数据，而这种操作被称之为分布式数据库。</p>
<p>世界上第一个分布式数据库是 SDD-1（System for Distributed Database），由 CCA（Computer Corporation of Amerca）</p>
<h2 id="DDBS-发展"><a href="#DDBS-发展" class="headerlink" title="DDBS 发展"></a>DDBS 发展</h2><h3 id="初期"><a href="#初期" class="headerlink" title="初期"></a>初期</h3><p>分布式数据库系统在 20实际 70 年代末时期诞生，在 80 年代进入了成当阶段，因为计算机功能的增强以及成本的下降，使得计算机广遍普及。也随着计算机网络的发展，降低了数据网络的传输费用，以及个人计算机的出现在计算机局域网的广泛发展。</p>
<p>这些都是分布式数据库系统的研制和实现所提供了必要的基础条件，无论是在民用还是军用领域中，各国都在分布式数据库系统的研究投入了大量的人力、物理和财力。</p>
<h4 id="德国与美国"><a href="#德国与美国" class="headerlink" title="德国与美国"></a>德国与美国</h4><p>例如德国的斯图加特大学所研制的 POREL 历经 11 年，投资 450w 德元，美国的 IBM 公司 20 世纪 70 年代由 San Jose 实验室所研制的 System R。</p>
<blockquote>
<p>San Jose 实验室后来更名为 IBM Almaden 研究中心。</p>
</blockquote>
<h4 id="西欧"><a href="#西欧" class="headerlink" title="西欧"></a>西欧</h4><p>美国加利副尼亚大学伯克利分校（Universiry of Californaia, Berkeley）研制的分布式 1n-gres 和荷兰阿姆斯特丹大学所研制的 Ingres，在 Unix&#x2F;PDP 上实现。</p>
<p>法国 IN-RIA 所研制的 SIRIUS-DELTA 系统和 IMAG 研究中心所研制的 MICROBE 系统。</p>
<h4 id="国内"><a href="#国内" class="headerlink" title="国内"></a>国内</h4><p>中国对分布数据库系统在 20 世纪 80 年代初期，国内一些科研单位和高等院校先后建立和实现了几个各具特色的分布式数据库，在这其中有中国科学院数学与系统科学研究院设计，和上海大学以及华东师范大学所合作实现的 C-POREL</p>
<p>以及上海大学和华东师范大学所合作实现的 C-POREL，以及武汉大学所研制的 WDDBS 和 WOODDBS ，东北大学研制的 DMU&#x2F;FO 系统等。</p>
<h3 id="标准化"><a href="#标准化" class="headerlink" title="标准化"></a>标准化</h3><p>在 1987 年，关系数据库最早的设计者之一 C.J.Date，在 “Distributed Database: A Closer Look” 中提出完全的、真正的分布式数据库管理系统所应该遵循的 12 条规则。</p>
<ol>
<li><p><strong>本地自治性</strong> (Local Autonomy)<br>本地站点的独立性 (Local site independence)，每个本地站点都可以作为一个独立、资质的集中的分布式数据库系统，并负责安全、并发控制、备份和恢复。</p>
</li>
<li><p><strong>中央站点独立性</strong> (Central site independence)<br>不依赖于中心站点（No Reliance On Central Site），网络中没有站带你依赖于中心站点或其他任何站点，所有的站点都具备相同的功能。</p>
</li>
<li><p><strong>可连续操作性</strong> (Continuous Operation)<br>失败的独立（Failure independence）即故障的对系统无影响，即使在节点故障的网络情况下，系统也可以连续运行。</p>
</li>
<li><p><strong>数据位置透明性和独立性</strong> (Location Transparency and Location Independ-ence)<br>位置的独立性 (Location Transparency)，用户不需要知道数据的位置就可以检索这些数据。</p>
</li>
<li><p><strong>数据分片的独立性</strong> (Fragmmentation Independence)<br>分裂的透明度（Fragmentation transparency）数据碎片对用户来说是独立的，用户只能看到一个逻辑数据库，用户不知道数据库片段的名称可以检索他们。</p>
</li>
<li><p><strong>数据复制的独立性</strong> (Fragrnentation Independence)<br>复制的透明度（Replication transparency）用户只能看到一个逻辑数据库，分布式数据库系统独立的选择访问数据库片段，对于用户来说分布式数据库系统可以独立管理所有片段。</p>
</li>
<li><p><strong>分布式查询处理</strong> (Distributed Query Processing)<br>分布式查询可能在多个不同的数据库站点执行，查询优化是分布式数据库独立执行的。</p>
</li>
<li><p><strong>分布式事务管理</strong> (Distributed Transanction Management)<br>一个事务可以在不同的站点上进行数据的更新，并且该事物是透明执行的。</p>
</li>
<li><p><strong>硬件独立性</strong> (Hardware Independence)<br>是指系统必须在任何硬件平台上运行。</p>
</li>
<li><p><strong>操作系统独立性</strong> (Operatnig System Independence)<br>该系统必须在任何操作系统中运行。</p>
</li>
<li><p><strong>网络系统的独立性</strong> (Operating System Independence)<br>必须在任何网络平台上运行。</p>
</li>
<li><p><strong>数据库管理系统独立性</strong> (DBMS Independenece)<br>系统必须支持任何厂商的数据库产品</p>
</li>
</ol>
<p>上述的 12 条是真正的分布式数据管理系统所应该遵循的 12 条规则，这也被行业而广泛的接受，有助于规划一个特定的分布式数据库系统的功能，从而也有助与区分一个真正普遍意义上的分布式数据库系统。</p>
<h3 id="商业化"><a href="#商业化" class="headerlink" title="商业化"></a>商业化</h3><p>20世纪90年代开始，分布式数据库开始进入商业化应用阶段，数据库厂商不断推出和改进自己的分布式数据库产品，来适应客户的需求和扩大市场份额。</p>
<p>对于分布式数据库系统，还需要网络技术的相互渗透和有机融合后得出的结果，他不仅带来了新的技术，还有了自己特色的理论基础和固有的技术难度，这就导致了分布式数据库系统的应用被延迟。</p>
<p>而对于现在，一些商业化的数据库产品如 ORACLE、IBM DB2、SYBASE、Microsoft SQL Server 以及 MySQL 等大都提供了对分布式数据库的支持（虽然支持的程度不同）</p>
<h3 id="本世纪的发展"><a href="#本世纪的发展" class="headerlink" title="本世纪的发展"></a>本世纪的发展</h3><p>随着 21 世纪下 Web 2.0 的兴起使得互联网上的站点数据大量增长从而促进了搜索引擎技术的萌芽，之后的 Google 或 百度等的数据也有海量的趋势增长。</p>
<h4 id="BigTable-与-GFS"><a href="#BigTable-与-GFS" class="headerlink" title="BigTable 与 GFS"></a>BigTable 与 GFS</h4><p>对于这些流量的日益增长，传统的分布式数据库已经不在适用，相应的也出现了新的分布式海量数据的组织和管理方式。在这其中 Google 所设计的 BigTable 用于管理结构化数据。</p>
<p>Big Table 通过利用 Google 分布式文件系统 (Google File System) 来实现数据的分布式存储和管理。</p>
<blockquote>
<p>Big Table 使用与 PB （Petabyte, 1PB&#x3D;10E15B），则表示拥有 1500000000000000 千万亿级数据处理和上千台的数据分布，因此他具有高可测量、高可用和高效以及高可靠的特点。</p>
</blockquote>
<h5 id="多级映射结构"><a href="#多级映射结构" class="headerlink" title="多级映射结构"></a>多级映射结构</h5><p>BigTable 不是关系型数据库而是多级映射的数据库结构，这种结果用于面向大规模的数据处理且容错性较强的自我管理系统，拥有 TB（Terabyte，万亿字节） 级的内存和 PB（Petabyte，千万亿字节	） 级的存储能力，每秒可以处理百万次的读写操作。</p>
<blockquote>
<p>虽然 BigTable 不支持关系型数据查询，但是却是建立在 GFS&#x2F;MapReduce 基础上的分布式存储大规模结构化数据的优秀的解决方案。</p>
</blockquote>
<h4 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h4><p>不同于 BigTable，HBase 利用了 Hadoop 分布式文件系统来管理和存储数据，同样不同于一般的关系数据库，他还是一个适合于非结构化数据存储的数据库，HBase 主要用于需要随机访问、实时读写大量数据的场景中。</p>
<h2 id="Not-Only-SQL"><a href="#Not-Only-SQL" class="headerlink" title="Not Only SQL"></a>Not Only SQL</h2><h3 id="关系型数据库的痛点"><a href="#关系型数据库的痛点" class="headerlink" title="关系型数据库的痛点"></a>关系型数据库的痛点</h3><p>对于关系型数据库，如 MySQL 或 Oracle 这样主流的关系性数据库而言，一个站点的表最为核心的就是用户的数据表，而当用户表达到 KB（Kilobyte，千字节）的情况下。</p>
<p>对单条数据的检索就会花上数秒或分钟级别的查询时间，而实际情况下会变得更加复杂，假设在查询的过程中又有几十个或几百个数据插入、编辑或删除等，一此时数据的查询的延迟将会轻易达到分钟级别。</p>
<p>在或者，需要查询的数据可能还需要设计到联合查询之类的操作，或者更为复杂的关联查询，则会造成数据库的性能大幅度的下降。</p>
<h3 id="CAP"><a href="#CAP" class="headerlink" title="CAP"></a>CAP</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/90539616823.png"></p>
<p>在 CAP 理论提出之前，很多的研究人员尝试将关系型数据库做成分布式架构的数据库，将数据的压力平坦分流到多个数据服务器上，而这期间很难保证原子性和 ACID</p>
<blockquote>
<p>原子性（Atomicity）、一致性（Consistency）、独立性（Isolation）、持久性（Durability）</p>
<blockquote>
<p>原子性指一个操作不可中断,要么全部成功,要么全部失败</p>
</blockquote>
</blockquote>
<p>如何平衡原子性和高性能数据库的方式，截至到在 20 世纪 90 年代初期的 Berkerly 大学 Eric Brewer 教授所提出的 CAP （Consistency Availability and Partition tolerance）理论所提出之前，该问题一直是关系型数据库的痛点。</p>
<p>布鲁尔定理(Brewer’s theorem)也被称之为CAP定理(CAP theorem),主要指出在分布式系统中的：</p>
<ol>
<li>一致性(Consistency), 数据一致更新，所有的数据变动都是同步的</li>
<li>可用性(Availability),每次请求都能获取到正确的响应，拥有良好的响应性能</li>
<li>分区容错性\可靠性(Partition tolerance),保证服务宕机时其他服务依然可以正常提供服务(系统中任意信息丢失或失败不会影响系统的继续运作)。</li>
</ol>
<p>对此 Brewer 教授给出的定理是：“任何分布式系统只可能满足两点，无法兼备三者”，并给出了忠告：“架构师不要将精力浪费在如何设计出兼备三者的完美的分布式系统，而是如何进行取舍”。</p>
<p>对此通过 CAP 定理,我们得知无法同时满足一致性、可用性、分区容错性这三个特性,因此假设:</p>
<ol>
<li><p>CP<br>即 一致性、分区容错性,牺牲掉了可用性保证了一致性,可能会有几个节点不可用,通常适用与银行系统。</p>
</li>
<li><p>AP<br>是可用性和分区容错性,舍弃掉了一致性,保障服务可用但可能会造成数据的冲突,可适用流量访问大对系统正常提供服务要求较高的系统;</p>
</li>
<li><p>CA<br>一旦集群中一台服务无法正常提供服务则会造成当前集群完全崩溃,适用与挑战者。</p>
</li>
</ol>
<h3 id="NoSQL"><a href="#NoSQL" class="headerlink" title="NoSQL"></a>NoSQL</h3><p>对 CAP 特性的放弃打来了一种更加新颖的非关系型数据库，和关系型数据库相反，他对事务性的要求并不严格。</p>
<p>对于非关系型数据库而言，我们假设数据库保证了最终一致性，即信息不会立即同步，而是经过了一定的时间才达到一致性，而不是像传统的关系型数据库，有很大可能会造成性能的下降。</p>
<h4 id="事务的持久性"><a href="#事务的持久性" class="headerlink" title="事务的持久性"></a>事务的持久性</h4><p>事务的提交可以被分为完全持久或延迟持久（通常被称之为迟缓提交），完全持久事务提交是同步的，假设在日志吸入磁盘后立马就会提交成功并进行发布。</p>
<p>而对于延迟持久事物的提交是异步的，他只要最终将事务持久性最终写入磁盘即可。完全和延迟事务的类型各有所长，一个服务能够同时包含完全和延迟持久事物，应该根据其业务需求进行设计。</p>
<h2 id="HBase-概述"><a href="#HBase-概述" class="headerlink" title="HBase 概述"></a>HBase 概述</h2><p>2006 年 Google 技术人员 Fay Chang 发表了 <em>Bigtable: A Distributed Storage System for Structure Data</em>，向人们介绍了分户是数据库，并可以在几台服务器崩溃的情况下继续提供高性能的服务。</p>
<p>进跟着 2007 年 Powerset inc. 内的技术人员根据该文章研发了 BigTable 的 Java 开源版本，即就是 HBase，虽然刚开始他只是 Hadoop 的一部分。</p>
<p>不久之后的2008年，HBase 成为了 Apache 的顶级项目，HBase 几乎实现了 BigTable 的所有特性，他也被称为开源的分布式非关系型数据库。</p>
<p>在随后的 2010 年 HBase 的开发速度打破了一直以来紧跟着 Hadoop 版本一致的管理，这是因为 HBase 的版本发布速度已经超越了 Hadoop。</p>
<h3 id="Hadoop-与-HBase"><a href="#Hadoop-与-HBase" class="headerlink" title="Hadoop 与 HBase"></a>Hadoop 与 HBase</h3><p>HBase 的存储基于 Hadoop ，他的崛起是因为高性能、高稳定、可管理的大数据应用平台，因此 Hadoop 实现了一个分布式文件系统 HDFS（Hadoop File System），有着高容错的特点，通常用来部署在价格低廉的硬件中，这也意味着基于 Hadoop 的 HBase 拥有着与与生俱来的扩展性吞吐量。</p>
<h3 id="优缺点"><a href="#优缺点" class="headerlink" title="优缺点"></a>优缺点</h3><p>HBase 所采用的是 Key&#x2F;Value 的存储方式，这也意味着即使处理海量数据，也不会导致数据的下降，反观 HBase 又是一个列式数据库，可以将子字段放在不同的集群中的机器上来分散负载压力。</p>
<p>而这样的存储结构和分布式的存储方式所带来的问题就是哪怕是存储少量的数据，HBase 并不会很快，但是对于海量数据的时候，他慢的没有关系型数据库慢。</p>
<p>因此只有在单表数据量超过千万，且高并发环境，对数据分析的需求较弱或者不需要经常使用，那么则需要使用 HBash。</p>
<h3 id="部署环境"><a href="#部署环境" class="headerlink" title="部署环境"></a>部署环境</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/4220400129300.png"><br>Hbase 从大到小划分为 <code>Master</code> 服务器和 <code>RegionServer</code> 服务器。其中 Master 为注册中心，而 <code>RegionServer</code> 即服务器端。</p>
<p>RegionServer 所保存的数据是直接存储在 Hadoop 的分布式文件系统中（HDFS）：</p>
<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/5507601686823.png"></p>
<p>而在一个完整的 HBash 环境中，RegionServer 非常依赖 ZooKeeper 服务，如果没有 ZooKeeper 则 HBase 的发展也会收到影响，因为在 HBase 的生态中， ZooKeeper 主要扮演一个类似管家的一个角色，管理了 HBase 所有的 RegionServer 信息（服务治理），其中包括具体的数据段存放在那个 RegionServer 中。</p>
<blockquote>
<p>ZooKeeper 提供了配置维护、域名服务、分布式服务、组服务、服务治理等功能</p>
</blockquote>
<p>客户端每次于 HBase 连接，就是与 ZooKeeper 通信，查询出需要链接的 RegionServer 需要连接，然后在链接 RegionServer。</p>
<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/3060745475915.png"></p>
<h4 id="RegionServer"><a href="#RegionServer" class="headerlink" title="RegionServer"></a>RegionServer</h4><p>RegionServer 是存放 Region 的容器，直观上了解就是服务器上的服务，简单来说一个服务只能安装一个 RegionServer（在未开虚拟化的情况下），当客户端从 ZooKeeper 获取到 RegionServer 的地址后，可以从 RegionServer 获取数据。</p>
<blockquote>
<p>客户端从 ZooKeeper 获取到 RegionServer 地之后，也可以从 RegionServer 中获取数据，以及插入、删除等所有操作都是直接操作 REgionServer，<strong>之后的 Master 只负责协调各种工作</strong>。</p>
</blockquote>
<p>当 HBash 负载均衡的时候，也有可能从一台 RegionServer 上把 RegionServer 到另一台 RegionServer 上。</p>
<h5 id="Region"><a href="#Region" class="headerlink" title="Region"></a>Region</h5><p>Region 是一段数据的集合，HBase 表中一般哟更有一个到多个 Region，他不能跨服务器，数据量小的时候一个 Region 足以存储所有数据，但是在数据量打的时候，HBase 会拆分 Region。</p>
<p>Region 是基于 HDFS 的，他的所有数据存取操作都是调用了 HDFS 的客户端接口来进行实现。</p>
<h4 id="Master"><a href="#Master" class="headerlink" title="Master"></a>Master</h4><p>Master 在整个 HBase 架构中负责协调各种工作，如建表、删表、移动、合并 Region 等操作，他们的通电就是需要跨越 RegionServer，这个操作由他本身来执行就显得很臃肿和不合适，因此就将这个操作放到了 Master 之上了。</p>
<p>这类结构的好处在于降低了 Master 的依赖，假设 Master 就诶点一般只有一个到两个，一旦宕机则会对集群造成单点故障，因此在 HBase 中，即使 Master 宕机了，集群依然可以正常工作。</p>
<h3 id="存储架构"><a href="#存储架构" class="headerlink" title="存储架构"></a>存储架构</h3><h4 id="列（Column）"><a href="#列（Column）" class="headerlink" title="列（Column）"></a>列（Column）</h4><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/3596626466712.png"></p>
<p>在 HBash 中最基本的存储单位就是列一个列或多个列形成一行 (row)，传统数据库是严格的行列对齐，比如这一行有两列，每列都有多个版本，多个版本的值都存储在单元格 (cell) 中，若干个列又可以被归类为一个列族。</p>
<h5 id="单元格（Call）"><a href="#单元格（Call）" class="headerlink" title="单元格（Call）"></a>单元格（Call）</h5><p>列族和列并不是唯一能够确定一个值的方式，通过单元格，一个列可以存储多个版本的值，多个版本的值都存储在一个单元格之中，为此通过 <code>version</code> 来进行区分。</p>
<p>对此唯一可以确定一条结果的表达式应该为：<strong>列族:列:版本号</strong> (rowkey:column family:column:version)</p>
<h5 id="列族（Column-family）"><a href="#列族（Column-family）" class="headerlink" title="列族（Column family）"></a>列族（Column family）</h5><p>在 HBase 中，若干个列可以组成列族（Column Family），在建表中不需要创建列。这是由于他可变且灵活，在这个过程中唯一需要确定的就是列族。</p>
<p>如过期时间，数据块缓存以及是否压缩都是定义在列组上，而不是定义在表上或列上。</p>
<p>同一个表中不同的列组可以有完全不同的属性配置，同一个列组内的列组都会有相同的属性。</p>
<blockquote>
<p>原因在于都是在同一个列族之中，而属性是定义在列族上的。</p>
</blockquote>
<p>列必须依赖列组的存在，在 HBase 中，一个列的签名会带着他的所属列族，列名称的规范在于 <strong>列族:列名</strong>，如：<em>brother:age、brother:name、parent:age、parent:name</em></p>
<p>他的主要的作用就是 HBase 会将列族的列尽量放到同一台服务器中，如果要想将列合并在一起，就需要定义相同的列族。</p>
<blockquote>
<p>想对于生产环境中，版本号是可以被忽略的，如果不填写版本号将会默认获取最后一个版本的数据返回。</p>
<p>每个列或单元格的值都被赋予了一个时间戳，这是由系统默认进行并制定的，也可以自定义显示。</p>
</blockquote>
<h4 id="行键（Row-Key）"><a href="#行键（Row-Key）" class="headerlink" title="行键（Row Key）"></a>行键（Row Key）</h4><p>每一个行 (row) 都有唯一的行键(row key)，来标定这个行的唯一性，而 row key 和 MySQL、Oracle 中的主键比起来就简单许多，行键是由用户指定的一串不重复的字符串，rowkey 会决定该 row 的存储位置，HBase 无法根据某个 列来进行排序，系统永远根据 rowkey 来进行排序，因此 rowkey 就决定 row 存储顺序的唯一凭证，例如：</p>
<ol>
<li>row-1</li>
<li>row-2</li>
<li>row-11</li>
</ol>
<p>那么经过 HBase 字典排序后则顺序为：</p>
<ol>
<li>row-1</li>
<li>row-11</li>
<li>row-2</li>
</ol>
<p>假设将数据插入 HBase ，用了之前存在的 rowkey，那么之前存在的 value 将会被更新，而之前所存在的 value 将会被存放在 column 的 call （即版本单元格）</p>
<h5 id="Region-和行的关系"><a href="#Region-和行的关系" class="headerlink" title="Region 和行的关系"></a>Region 和行的关系</h5><p>一个 Region 就是多个行的集合，Region 中的行按照键 (rowkey) 的字典来进行排序。</p>
<h3 id="高离散"><a href="#高离散" class="headerlink" title="高离散"></a>高离散</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/sql/hbash/1.%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E8%BF%B0.md/3046903189300.png"><br>相对与关系性数据库，HBase 内的行都是离散的，所以一个行里面的列无论被划分到了不同的服务中，行的概念都被进行一定的削弱。</p>
<p>因为离散存储的关系，在 HBase 中，每个存储或编辑的语句都需要写出数据要被存储到那个单元格，即：<em>表,行,列族:列名</em> 进行定义，也就是说要精准的写出要将数据存储到那位置中。</p>
<p>而对比关系型数据库，只需要通过 insert 语句来一次性将数据写入在数据库中。</p>

	

	

</article>




	<article>
	
		<h1><a href="/2022/04/21/databases/hbase/2021-11-22-Hadoop+Zookeepr+HBase/">Hadoop+Zookeeper+HBase</a></h1>
	
	<div class="article__infos">
		<span class="article__date">2022-04-21</span><br />
		
		
			<span class="article__tags">
			  	<a class="article__tag-none-link" href="/tags/databases/" rel="tag">databases</a> <a class="article__tag-none-link" href="/tags/hbase/" rel="tag">hbase</a>
			</span>
		
	</div>

	

	
		<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/29141209211166.png"><br>Hbase 是一个依赖于 Hadoop+ZooKeeper 的开源的非关系型数据库，而 Hadoop 是一个 Google File System 论文的实现，用于支持数据密集型分布式应用程序。在此之前 HBase 只是 Hadoop 的子项目，而 Hadoop 是在 Google File System 在 2003 年之后的 2004 年 Doug Cutting 基于 MapReduce、Nutch 搜索引擎实现了自己的分布式文件存储系统被命名为 *NDFS(Nutch Distributed File System)*，而 Google 自己的分布式文件存储系统被称之为 <em>GFS(Google File System)</em></p>
<p>同年 Google 又发布了一篇技术学术论文，展示了 MapReduce 编程模型，用于大规模数据集的并行分析运算，而后的 1 年时间里，也就是 2005 年,Docug Cutting 基于 MapReduce 在 Nutch 搜索引擎中实现了这一功能并命名为 MapReduce，之后 Diug Cutting 被 Yahoo 收购后改名 Hadoop，</p>
<p>2006 年<em>Bigtable: A Distributed Storage System for Structured Data</em>  发布而后 Diug Cutting 在自己的 Hadoop 进行集成了 Bigtable 后加入到 Hadoop 中命名为 HBase，这也意味着 HBase 具有高性能、高可扩展性基于 HDFS 的文件存储系统，用于存储大规模结构化数据，适用于云计算。</p>
<h2 id="HBase-核心"><a href="#HBase-核心" class="headerlink" title="HBase 核心"></a>HBase 核心</h2><h3 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h3><h4 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h4><p>HBase 核心就是 HDFS（Hadoop File System）和 MapReduce，由于 HBase 是基于 HDFS 上运行，每个存储的文件也被称之为 HDFS 文件，具有高度的容错能力，可在部署在低成本的硬件中，并提供高吞吐量的访问，适用于具有大型数据集的应用程序。</p>
<p>大概设计上是通过 <em>The Google File System</em> 进行实现，阅读 HDFS 的 <a target="_blank" rel="noopener" href="https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html">官方文档</a> 基本上等同于阅读 <a target="_blank" rel="noopener" href="https://research.google/pubs/pub51/">The Google File System
</a></p>
<table>
<thead>
<tr>
<th>id</th>
<th>Name</th>
<th>Info</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>硬件故障</td>
<td>HDFS 通常可能由几百台或几千台计算机组成，每台计算机都村粗文件系统数据的一部分，实际上大量的组件可能会出现故障概率，因此 HDFS 可以检测故障并从中快速且自动回复故障是架构的核心目标</td>
</tr>
<tr>
<td>2</td>
<td>流数据访问</td>
<td>流式数据访问的特点就是像水一样，不是一次写入而是一点一点写入，如果是全部收到数据后在处理，那么延迟会加大，会消耗大量的内存。HDFS 更多的是为了批处理而进行设计，重点的数据访问的高吞吐量而不是数据访问的低延迟。</td>
</tr>
<tr>
<td>3</td>
<td>大型数据集</td>
<td>在 HDFS 上运行的程序具有大型数据集，HDFS 中典型的文件大小为 GB~TB ,因此 HBase 也支持大文件，应提供高举和数据贷款并扩展到单个集群中的数百个节点</td>
</tr>
<tr>
<td>4</td>
<td>简单的一致性模型</td>
<td>HDFS 应用程序对文件采用一次写入多次读取的访问模型，文件一旦创建后写入和关闭除追加和截断意外无需更改。支持i将内容追加到文件末尾但不能在任意节点中更新，这简化了一致性问题并实现了高吞吐量数据访问</td>
</tr>
<tr>
<td>5</td>
<td>移动计算比移动数据更便宜</td>
<td>应用程序请求的计算在他所操作的数据附近所执行的，那么他的效率会搞得很多，当数据集规模较大的时候依然如此。</td>
</tr>
<tr>
<td>6</td>
<td>跨异构硬件和软件平台的可移植性</td>
<td>HDFS 被设计易于从移植到另一个平台，可移植性有益于 HDFS 作为大量应用程序的首选平台</td>
</tr>
</tbody></table>
<p>上述六个是 HBase 的假设和目标，来让 HBase 成为一个非关系型数据库，在 Eric Brewer 的 CAP 理论中，HBase 属于 CP 类系统，保证了一致性但对可用性或缺，可能会有几个节点不可用,通常适用与银行系统。</p>
<h5 id="Namenode-and-Datanode"><a href="#Namenode-and-Datanode" class="headerlink" title="Namenode and Datanode"></a>Namenode and Datanode</h5><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/182035415211163.png"><br>HDFS 是一个主&#x2F;从架构，集群由 NameNode 组成，作为主服务器，用于管理文件系统命名空间并调节客户端对文件的访问。而 Datanode 管理附加到运行他们的节点存储，HDFS 文件系统命名空间，并允许用户数据存储在文件夹中，在内部被拆分为一个或多个块，这些块都存储在 DataNode 中。</p>
<p>NameNode 执行文件系统命名空间操作，如打开、关闭和重命名目录，并确定块到 DataNode 的映射，DataNode 负责为来自文件系统客户端的读取和请求提供服务，DataNode 还根据 NameNode 的执行来执行块的创建和删除以及复制。</p>
<h4 id="Hadoop-HA"><a href="#Hadoop-HA" class="headerlink" title="Hadoop HA"></a>Hadoop HA</h4><p>Hadoop 分为 HA(High Avaliable，高可用性)模式和非 HA 模式，在生产环境中 Hadoop 都应为 HA 模式，以保障整个集群中 Namenode 节点没有单点故障的问题，HA 模式主要用于解决单点故障。</p>
<p>如果一个集群太依赖一个点，而那个点宕掉了就算其他集群是好的，而整个集群也相当于整体瘫痪，他通常会出现在元数据存储节点中，而这种节点通常出现在 namenode 上，Hadoop HA 的做法就是启动两个或多个 Namenode，一个处于 active(活跃) 状态，其他的机器则处于 standby(后备机) 状态，他只是单纯同步 active 数据，当活跃机宕掉后可直接自动切换过去，这也被称之为 HA 模式。</p>
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>Zookeeper 是一个轻量级的分布式架构集群，同时也是 Hadoop 和 HBase 的重要组件，提供了配置维护、域名服务、分布式同步、组服务、服务治理等功能，Zookeeper 的集成使得我们可以直接依赖 Zookeeper 来维护节点，而不是自己在编写节点的注册、取消、维持和存活检测、节点失效等代码。</p>
<h2 id="Hadoop-1"><a href="#Hadoop-1" class="headerlink" title="Hadoop"></a>Hadoop</h2><h3 id="Vagrant"><a href="#Vagrant" class="headerlink" title="Vagrant"></a>Vagrant</h3><p>在正式安装 Hadoop 之前我们需要依赖于 vagrant 以及 Oracle VM VirtualBox 来搭建 Centos 系统环境，共为 5 台机器。</p>
<p>前三台分别被称之为 nn01、nn02，作为 <code>namenode</code>，后三台作为 <code>datanode</code>，分别为 dn01、dn02、dn3。</p>
<p>对于第一次使用 vagrant 作为主要的虚拟机管理工具的读者，我们首先需要通过 <code>vagrant init centos/7</code> 然后直接 <code>vagrant up</code> 即可。</p>
<p>但由于一系列不可抗拒的因素国内可能通过这样下载很慢，我们也可以借助工具来下载他的 <code>.box</code> 文件，下载后可以通过下述几个命令来进行启动：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vagrant init &#x27;D:\Vagrant Dabatables\hbase\CentOS-7-x86_64-Vagrant-2004_01.VirtualBox.box&#x27;</span><br><span class="line">vagrant add box CentOS-7-x86_64-Vagrant-2004_01.VirtualBox.box --name centos/7</span><br><span class="line">vagrant up</span><br></pre></td></tr></table></figure>

<p>当看到 vagrant up 成功启动 Centos 之后，接下来输入 <code>vagrant ssh</code> 以连接虚拟机的 Shell 进行操作，除此我们还可以使用 <code>supend(挂起)、reload(重启)、halt(关机)、status(查看状态)</code> 等参数提升效率。</p>
<p>在上述的操作过程中（泛指 <code>vagrant init</code>） 之后会产生一个 Vagrantfile 文件，我们需要修改并设置与物理机共享的文件夹，以及固定的 IP 等配置：</p>
<blockquote>
<p>尽管 <code>config.vm.box</code> 可能会报错，改为 <code>.box</code> 所在地址即可。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># Create a private network, which allows host-only access to the machine</span><br><span class="line"># using a specific IP.</span><br><span class="line">config.vm.network &quot;private_network&quot;, ip: &quot;192.168.115.10&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Create a public network, which generally matched to bridged network.</span><br><span class="line"># Bridged networks make the machine appear as another physical device on</span><br><span class="line"># your network.</span><br><span class="line">config.vm.network &quot;public_network&quot;</span><br><span class="line"></span><br><span class="line"># Share an additional folder to the guest VM. The first argument is</span><br><span class="line"># the path on the host to the actual folder. The second argument is</span><br><span class="line"># the path on the guest to mount the folder. And the optional third</span><br><span class="line"># argument is a set of non-required options.</span><br><span class="line">config.vm.synced_folder &quot;src/&quot;, &quot;/srv/website&quot;</span><br></pre></td></tr></table></figure>

<h3 id="Host-Configuration"><a href="#Host-Configuration" class="headerlink" title="Host Configuration"></a>Host Configuration</h3><h4 id="Host-name"><a href="#Host-name" class="headerlink" title="Host name"></a>Host name</h4><p>在了解到 vagrant 基本的使用方法后我们可以搭建 HBase 所需要的环境，当然这是通用的，我们只演示 nn01 的配置方法，之后 nn02、dn01、dn02、dn03 跟着随后即可，可以说名称和IP不一样。</p>
<p>通过 <code>vi /etc/hosts</code> 文件将所有机器的 IP 和机器名都配置到 hosts 文件中，以方便我们使用 <code>ssh</code> 根据对应的节点名称来进行连接（对于网段可以根据自身环境来进行配置）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">192.168.115.10 nn01</span><br><span class="line">192.168.115.11 nn02</span><br><span class="line">192.168.115.12 dn01</span><br><span class="line">192.168.115.13 dn02</span><br><span class="line">192.168.115.14 dn03</span><br></pre></td></tr></table></figure>

<p>为防止之后通过 <code>ssh nn1</code> 的时候可能会提示 Permission denied (publickey,gssapi-keyex,gssapi-with-mic). 的错误消息，我们可以通过 <code>vi /etc/ssh/sshd_config</code> 来进行更改配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># To disable tunneled clear text passwords, change to no here!</span><br><span class="line">PasswordAuthentication yes</span><br><span class="line">#PermitEmptyPasswords no</span><br><span class="line">#PasswordAuthentication no</span><br><span class="line"></span><br><span class="line"># Change to no to disable s/key passwords</span><br><span class="line">#ChallengeResponseAuthentication yes</span><br><span class="line">ChallengeResponseAuthentication no</span><br></pre></td></tr></table></figure>

<p>最后通过 <code>sudo systemctl restart sshd</code> 来重启下 sshd 服务，在重新进行测试即可，为区分节点之间的名称建议通过 <code>hostnamectl set-hostname &lt;name&gt;</code> 来修改当前主机名称以方便之后在 ssh 还是在控制台内的查看集群信息。</p>
<p>同样的还有 <code>/etc/sysconfig/network</code> 文件下配置当前的 hostname 之后通过 <code>service network restart</code> 重新穷下。</p>
<h4 id="Shell-No-password"><a href="#Shell-No-password" class="headerlink" title="Shell No password"></a>Shell No password</h4><p>以 <code>useradd hadoop</code> 新建用户 hadoop 并为其设置 <code>passwd hadoop</code> 密码后通过 <code>sudo chmod u+w /etc/sudoers</code> 将 hadoop 添加到 sudoers 列表，向 <code>/etc/sudoers</code> 文件中添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop ALL=NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>使用 <code>ssh-keygen -t rsa</code> 生成 id_rsa.pub 后以 <code>scp</code> 将自身的 rsa 密钥分发给 nn01，<code>scp .ssh/id_rsa.pub hadoop@nn01:/home/hadoop/.ssh/nn02_keys</code>，当然也包括自己的，这将使得可以自己 shell 免密连接自己，并设置目录权限：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd .ssh/</span><br><span class="line">cat dn01_keys dn02_keys dn03_keys nn01_keys nn02_keys &gt;&gt; authorized_keys</span><br><span class="line">sudo chmod 700 /home/hadoop/</span><br><span class="line">sudo chown hadoop:hadoop ./.ssh/</span><br><span class="line">sudo chmod 700 .ssh/authorized_keys</span><br></pre></td></tr></table></figure>

<p>最后使用 <code>scp authorized_keys hadoop@nn02:/home/hadoop/.ssh/</code> 将 <em>authorized_keys</em>  文件分发给 nn02、dn01、dn02、dn03 机器中。</p>
<h4 id="Java-1-8-install"><a href="#Java-1-8-install" class="headerlink" title="Java 1.8 install"></a>Java 1.8 install</h4><p>在安装和配置 Hadoop 之前，我们需要安装 Java 环境且至少实在 1.8 版本以上，我们直接从 <a target="_blank" rel="noopener" href="https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html">https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html</a> 下载系统对应的文件并通过 <code>sudo vi /etc/profile</code> 添加环境变量后刷新即可 <code>source /etc/profile</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/jdk1.8.0_202</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<p>为了防止普通用户无法使用 Java 还需要设置普通用户的环境变量 <code>sudo vi ~/.bashrc</code> 同样的向此文件添加 JDK 所在位置并使用 <code>source ~/.bashrc</code> 刷新即可：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/jdk1.8.0_202</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure>

<blockquote>
<p>正常环境下直接通过 <code>/etc/profile</code> 配置全局的环境变量即可，可根据实际环境自行选择</p>
</blockquote>
<h3 id="单机模式与集群模式"><a href="#单机模式与集群模式" class="headerlink" title="单机模式与集群模式"></a>单机模式与集群模式</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/537634301229590.png"><br>当上述配置完成之后，开始安装 Hadoop，这也是 HBase 的运行基础，在此之前我们先看下当前系统的磁盘最大分区，以决定是否要修改日志存储目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs        237M     0  237M   0% /dev</span><br><span class="line">tmpfs           244M     0  244M   0% /dev/shm</span><br><span class="line">tmpfs           244M  4.5M  240M   2% /run</span><br><span class="line">tmpfs           244M     0  244M   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda1        40G  3.4G   37G   9% /</span><br><span class="line">tmpfs            49M     0   49M   0% /run/user/1000</span><br></pre></td></tr></table></figure>

<p>我的系统分区最大是 <code>/</code> 也就是说无需更改他的日志存储路径，如果你的磁盘大小和我的不一样那么建议之后在 Hadoop 的配置文件中更改日志存储位置即可，可通过清华大学镜像站直接进行下载 Hadoop 并解压：<a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.3.1/">https://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-3.3.1/</a></p>
<p>通过 <code>tar zxvf hadoop-3.3.1.tar.gz</code> 解压文件并重命名为 hadoop(<code>mv hadoop-3.3.1 hadoop</code>)并移动到 <code>usr/local</code> 文件夹中，之后在 <code>~/.bashrc</code> 添加环境变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># Hadoop_Home</span><br><span class="line">export HADOOP_HOME=/usr/local/hadoop</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<blockquote>
<p>保证可以输入 <code>hadoop</code> 出现参数提示即可，但不要忘记使用 <code>source ~/.bashrc</code> 刷新配置，以及在 <code>/usr/local</code> 目录那为 hadoop 设置用户组为 hadoop（<code>sudo chown hadoop:hadoop /usr/local/hadoop/*</code>）</p>
</blockquote>
<p>进入到 <code>/usr/local/hadoop/etc/hadoop</code> 目录下配置 <code>core-site.xml</code> 文件并写入节点名称</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;hdfs://nn01:8020&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>之后编辑 <code> hdfs-site.xml</code> 文件被指 HDFS 相关属性并增加数据备份(dfs.replication)、namenode\datanode 存储文件位置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:///data/hadoop/hdfs/nn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">    &lt;property&gt;</span><br><span class="line">        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">        &lt;value&gt;file:///data/hadoop/hdfs/dn&lt;/value&gt;</span><br><span class="line">    &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>并建立 datanode&#x2F;namenode 存储文件以及为其分配权限：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd /</span><br><span class="line">sudo mkdir -p /data/hadoop/hdfs/nn</span><br><span class="line">sudo mkdir -p /data/hadoop/hdfs/dn</span><br><span class="line">sudo chown hadoop:hadoop data/*</span><br></pre></td></tr></table></figure>

<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/79735502217457.png"></p>
<p>切换到 hadoop 用户使用 <code> hdfs namenode -format</code> 来格式化 namenode 后启动单机模式 <code>bash /usr/local/hadoop/sbin/start-dfs.sh</code>，结束后访问 <code>http://&lt;ip&gt;:9870/</code> 即可看到 Hadoop 单机模式的控制台页面来验证上述配置的正确，之后将上述配置全部在 nn02、dn01、dn02、dn03 中在配置一遍。</p>
<blockquote>
<p>可使用 <code>bash /usr/local/hadoop/sbin/stop-dfs.sh</code> 来停止单机模式</p>
</blockquote>
<p>并在所有机器上执行 <code>hdfs namenode -format</code> 用于格式化来调试，并启动 <code>bash /usr/local/hadoop/sbin/start-dfs.sh</code> 进行单机启动来保证所有机器配置都是正确的，之后在所有节点中删除数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /data/hadoop/hdfs/nn/*</span><br><span class="line">rm -rf /data/hadoop/hdfs/dn/*</span><br></pre></td></tr></table></figure>

<p>之后在 nn01 节点中使用 <code>hdfs namenode</code> 来启动主节点，之后在其他节点中启动 <code>start-dfs.sh</code> 即可将此连接为一个集群。</p>
<p>在没有配置 ZooKeeper 之前，datanode 和 namenode 是通过 <code>core-site.xml</code> 中的 <code>fs.defaultFS</code> 属性去连接 namenode 的 8020 端口，并建立连接，在没有 ZooKeeper 之前，是不允许有两个 Namenode 节点存在的，也就是非HA模式，他只会有一个 Namenode 节点，对于其他的都会被 Hadoop 视为 Datanode 节点，在后续步骤中我们要完成 Hadoop HA 的配置。</p>
<h2 id="Hadoop-HA-and-ZooKeeper"><a href="#Hadoop-HA-and-ZooKeeper" class="headerlink" title="Hadoop HA and ZooKeeper"></a>Hadoop HA and ZooKeeper</h2><h3 id="ZooKeeper-install-x2F-run"><a href="#ZooKeeper-install-x2F-run" class="headerlink" title="ZooKeeper install &#x2F; run"></a>ZooKeeper install &#x2F; run</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/498362619211164.png"><br>在开始 ZooKeeper 之前我们已经了解到为什么 Hadoop HA 需要 ZooKeeper 了，ZooKeeper 同样是 Apache 基金会下的开源项目，他用于分布式应用程序协调服务，是 Google Chubby 的开源实现，为分布式应用提供一致性服务，包括了配置维护、域名服务、配置同步以及组服务等。</p>
<p>ZooKeeper 集群最好是奇数，这样会有利于仲裁，感兴趣的读者可以去了解下 Raft（Reliable,Replicated,Redundant,And Fault-Tolerant）这和 Hadoop HA 有异曲同工之妙。</p>
<p>以 <code>useradd zookeeper</code> 新建用户 zooke 并为其设置 <code>passwd zookeeper</code> 密码后通过 <code>sudo chmod u+w /etc/sudoers</code> 将 hadoop 添加到 sudoers 列表，向 <code>/etc/sudoers</code> 文件中添加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop  ALL=NOPASSWD:ALL</span><br><span class="line">zookeeper ALL=NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>之后通过清华大学开源镜像站获取 <a target="_blank" rel="noopener" href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz</a> 并解压到 <code>/usr/local/</code> 中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar zxvf apache-zookeeper-3.6.3.tar.gz</span><br><span class="line">sudo mv apache-zookeeper-3.6.3/ /usr/local/zookeeper</span><br><span class="line">sudo chown -R zookeeper:zookeeper /usr/local/zookeeper</span><br></pre></td></tr></table></figure>

<p>通过在 <code>/etc/profile</code> 增加全局变量后以 <code>source /etc/profile</code> 命令让配置生效</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ZOOKEEPER=/usr/local/zookeeper</span><br><span class="line">export PATH=$PATH:$ZOOKEEPER/bin</span><br></pre></td></tr></table></figure>

<p>进入到 <code>/usr/local/zookeeper/conf</code> 目录下将 <code>zoo_sample.cfg</code> 文件复制一份并改名 <strong>zoo.cfg</strong>：<code>cp -r zoo_sample.cfg zoo.cfg</code> ，并编辑 <code>daraDir</code> 这一行的文件夹位置为 <code>/data/zookeeper</code>。</p>
<p>在 <code>/usr/local/zookeeper/bin/</code> 文件内的 <code>zkEnv.sh</code> 文件中增加 <code>ZOO_LOG_DIR=/data/logs/zookeeper</code> 日志存放目录并新建目录和权限的设置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /data/zookeeper</span><br><span class="line">sudo chown zookeeper:zookeeper /data/zookeeper/</span><br><span class="line">sudo mkdir /data/logs</span><br><span class="line">sudo mkdir /data/logs/zookeeper</span><br><span class="line">sudo chown -R zookeeper:zookeeper /data/logs/zookeeper</span><br></pre></td></tr></table></figure>

<p>然后在 <code>/data/zookeeper</code> 新建一个文件命名为 myid，并写入这台服务器的 Zookeeper id，取值范围为 1~255，配置如下：</p>
<table>
<thead>
<tr>
<th>id</th>
<th>host</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>nn01</td>
</tr>
<tr>
<td>2</td>
<td>nn02</td>
</tr>
<tr>
<td>3</td>
<td>dn01</td>
</tr>
<tr>
<td>4</td>
<td>dn02</td>
</tr>
<tr>
<td>5</td>
<td>dn03</td>
</tr>
</tbody></table>
<p>通过 <code>zkServer.sh start</code> 启动 Zookeeper，之后使用 <code>zkCli.sh</code> 测试是否可以连接上，如无报错执行下列命令查看 ZooKeeper 根目录。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] ls /</span><br><span class="line">[zookeeper]</span><br></pre></td></tr></table></figure>

<p>之后 <code>zkServer.sh stop</code> 来停止 Zookeeper 的运行并清空数据文件夹和日志文件夹，并在 <code>/usr/local/zookeeper/conf/zoo.cfg</code> 添加节点信息：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">server.1=nn01:2888:3888</span><br><span class="line">server.2=nn02:2888:3888</span><br><span class="line">server.3=dn01:2888:3888</span><br><span class="line">server.4=dn02:2888:3888</span><br><span class="line">server.5=dn03:2888:3888</span><br></pre></td></tr></table></figure>

<p>此时在执行过 <code>zkServer.sh start</code> 后 Zookeeper 会将配置中所有的节点连接成一个集群，可以通过 <code>zkServer.sh status</code> 来进行查看：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@nn01 local]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost. Client SSL: false.</span><br><span class="line">Mode: leader</span><br><span class="line"></span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost. Client SSL: false.</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[zookeeper@dn01 zookeeper]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost. Client SSL: false.</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[zookeeper@dn02 zookeeper]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost. Client SSL: false.</span><br><span class="line">Mode: follower</span><br><span class="line"></span><br><span class="line">[zookeeper@dn03 zookeeper]$ zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /usr/local/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost. Client SSL: false.</span><br><span class="line">Mode: follower</span><br></pre></td></tr></table></figure>

<h4 id="自启动脚本"><a href="#自启动脚本" class="headerlink" title="自启动脚本"></a>自启动脚本</h4><p>自启动脚本在 <code>etc/init.d</code> 下，通过 root 账号来进行操作，我们通过建立 <code>zookeeper</code> 文件后写入下述内容，即可通过 <code>service zookeeper status | start | stop</code> 来进行对 zookeeper 的操作。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">chkconfig:2345 80 10</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">description: zookeeper service</span></span><br><span class="line">export JAVA_HOME=&quot;/usr/jdk1.8.0_202&quot;</span><br><span class="line">RETVAL=0</span><br><span class="line">start() &#123;</span><br><span class="line">    su zookeeper -c &quot;bash /usr/local/zookeeper/bin/zkServer.sh start&quot;</span><br><span class="line">&#125;</span><br><span class="line">stop() &#123;</span><br><span class="line">    su zookeeper -c &quot;bash /usr/local/zookeeper/bin/zkServer.sh stop&quot;</span><br><span class="line">&#125;</span><br><span class="line">status() &#123;</span><br><span class="line">    su zookeeper -c &quot;bash /usr/local/zookeeper/bin/zkServer.sh status&quot;</span><br><span class="line">&#125;</span><br><span class="line">case $1 in</span><br><span class="line">start)</span><br><span class="line">    start</span><br><span class="line">;;</span><br><span class="line">status)</span><br><span class="line">    status</span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line">    stop</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">exit $RETVAL</span><br></pre></td></tr></table></figure>

<blockquote>
<p>为脚本赋予可执行权限 <code>sudo chmod +x /etc/init.d/zookeeper</code>  添加 Zookeeper 在自启动，重启机器后通过 <code>jps</code> 命令再次查看服务是否正常启动。</p>
</blockquote>
<h3 id="Hadoop-HA-1"><a href="#Hadoop-HA-1" class="headerlink" title="Hadoop HA"></a>Hadoop HA</h3><p>Haddoop HA (High Avaliable，高可用) 的主要作用就是 <strong>保证当一个 namenode 宕机的时候，另一台 namenode 可以立即切换来替代宕掉的 namenode</strong>，这样就大概上解决了单点故障的问题。这样的原理基本就是同时启动两台 namenode，一台是活跃状态(active)，另一台则是处于 <strong>支持(standby)</strong> 状态，其主要的作用就是将处于 <strong>active</strong> 状态的机器上所做过的事情进行同步，以方便在 active 挂掉的时候 standy 可以无缝切换。</p>
<p>在 Hadoop HA 模式下，主要通过 ZooKeeper 来进行对节点的维护，因此 Hadoop HA 的搭建与 ZooKeeper 密不可分，而 ZooKeeper 在整个流程当中都处于服务治理、故障检测、节点维护的身份进行工作。</p>
<h4 id="JournalNode"><a href="#JournalNode" class="headerlink" title="JournalNode"></a>JournalNode</h4><p>日志节点(JournalNode) 主要的作用就是在 standby 同步 active 这个流程中充当与数据同步的方式，standby 就是通过 journalnode 集群来同步 active 节点的操作。</p>
<p>JournalNodde 与 dataname 和 namenode 一样，都是 Hadoop 集群中的角色，只不过他主要用于同步 namenode 之间的操作，以防止脑裂现象。</p>
<blockquote>
<p>假设测试环境的配置不是很好，那么可以通过在 <code>hdfs-site.xml</code> 文件内添加 <code>dfs.qjournal.start-segment.timeout.ms</code> 的配置，来增加和 JournalNode 集群之间的超时时间</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.qjournal.start-segment.timeout.ms&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;60000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<h5 id="手动-Failover"><a href="#手动-Failover" class="headerlink" title="手动 Failover"></a>手动 Failover</h5><p>failover 的配置分为手动和自动，本文我们选择手动进行操作，failover 即故障切换或故障转移。当一个 Haddop 中有一台 namenode 宕掉了，那么就可以将另外台处于 standby 状态的机器切换成 active 的 namenode 。</p>
<p>这样就可以大幅程度上减少了单点故障所给服务集群带来的影响和损失，在 failover 没有运用之前，相对于单点应用只有一个台 namenode，假设这台刚好宕掉了，那么集群就约等于无法正常提供服务了。当 failover 配置成功后，当这台 namenode 宕掉了还会有另一台 namenode 进入 active 状态从而继续提供服务。</p>
<p>修改所有 namenode 机器上的 <code>/usr/local/hadoop/etc/hadoop/hdfs-site.xml</code> 文件并写入以下配置，分别作为服务id，以及服务 id 内所含有的 namenode：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mycluster&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn01,nn02&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn01&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn01:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.rpc-address.mycluster.nn02&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn02:8020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.mycluster.nn01&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn01:9870&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.http-address.mycluster.nn02&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn02:9870&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;qjournal://nn01:8485;nn02:8485;dn01:8485;dn02:8485;dn03:8485/mycluster&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;/data/hadoop/hdfs/jn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">   &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">   &lt;value&gt;</span><br><span class="line">       sshfence</span><br><span class="line">       shell(/bin/true)</span><br><span class="line">   &lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>dfs.nameservices</td>
<td>服务 id</td>
</tr>
<tr>
<td>2</td>
<td>dfs.ha.namenodes.mycluster</td>
<td>服务 id 内所含有的 namenode</td>
</tr>
<tr>
<td>3</td>
<td>dfs.namenode.rpc-address.mycluster.nn01</td>
<td>设置两个 Namenode 的 RPC 访问地址</td>
</tr>
<tr>
<td></td>
<td>dfs.namenode.rpc-address.mycluster.nn02</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>dfs.namenode.http-address.mycluster.nn01</td>
<td>设置两个 Namenode 的 HTTP 访问地址</td>
</tr>
<tr>
<td></td>
<td>dfs.namenode.http-address.mycluster.nn02</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>dfs.namenode.shared.edits.dir</td>
<td>配置 journalnode 集群的访问地址</td>
</tr>
<tr>
<td>6</td>
<td>dfs.client.failover.proxy.provider.mycluster</td>
<td>配置 dfs 客户端的类名，以判断哪个 namenode 是活跃的</td>
</tr>
<tr>
<td>7</td>
<td>dfs.ha.fencing.methods</td>
<td>故障迁移方法，通过 ssh 直接过去将被判断为故障的 namenode 直接杀掉，以防止脑裂现象</td>
</tr>
<tr>
<td></td>
<td>dfs.ha.fencing.ssh.private-key-files</td>
<td>ssh 免密登录的 id_rsa 位置，以实现上面的故障迁移</td>
</tr>
<tr>
<td>8</td>
<td>dfs.journalnode.edits.dir</td>
<td>journalnode 的数据文件夹位置</td>
</tr>
<tr>
<td>9</td>
<td>dfs.ha.fencing.methods</td>
<td>隔离机制方法 (多个机制用换行分割，即每个机制暂用一行)</td>
</tr>
</tbody></table>
<p>之后修改 <code>core-site.xml</code> 文件，将之前的 <code>fd.defaultFS</code> value 值改为 <code>hdfs://mycluster</code> 。此前的 <code>fs.defaultFS</code> 内是需要单独配置 8020 端口的，但是这个端口被移植到了 hdfs-site.xml 中，因此在 core-site.xml 中不需要专门填写一个端口，他们已经组成了一个集群，只需要向外暴漏 nameserver ID 在 ZooKeeper 集群中找出 active 的 namenode 所对应的 ip:port 来进行连接。</p>
<p>并为 journalnode 建立需要的文件夹和赋予权限：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir /data/hadoop/hdfs/jn</span><br><span class="line">sudo chown -R hadoop:hadoop /data/hadoop/</span><br></pre></td></tr></table></figure>

<p>在此之前我强烈的建议你清口所有 hadoop 生成过数据的目录，否则你可能会在启动 journalnode 之后出现一系列的问题，比如 <code>hdfs namenode -format</code> 格式化失败等：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo rm -rf /data/hadoop/hdfs/dn/*</span><br><span class="line">sudo rm -rf /data/hadoop/hdfs/nn/*</span><br><span class="line">sudo rm -rf /data/hadoop/hdfs/jn/*</span><br><span class="line">sudo rm -rf /tmp/*</span><br></pre></td></tr></table></figure>

<p>然后在所有节点中启动 journalnode，数量必须为奇数即可，分别执行 <code>hdfs --daemon start journalnode</code> 之后通过 <code>jps</code> 来查看是否 journalnode 节点启动成功：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">2900 JournalNode</span><br><span class="line">2938 Jps</span><br></pre></td></tr></table></figure>

<blockquote>
<p>可通过 <code>hdfs --daemon stop journalnode</code> 停止 journalnode 节点</p>
</blockquote>
<p>然后在 nn01 上使用 <code>hdfs namenode -format</code> 来进行格式化，然后在在启动 Namenode ：<code>hdfs namenode</code>。</p>
<p>切换到 nn02 中同步 namenode 让他完全做好成为备份机(standby) 的准备 <code>hdfs namenode -bootstrapStandby</code>，然后在 dn01~dn03 机器中启动 HDFS: <code>start-dfs.sh</code> 使得启动 Datanode 节点后使用 <code>jps</code> 进行查看节点的启动状态：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">2615 JournalNode</span><br><span class="line">2895 DataNode</span><br><span class="line">3231 Jps</span><br></pre></td></tr></table></figure>

<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/376853600211165.png"></p>
<p>最后访问 <code>&lt;namenode ip&gt;:9870</code> 可以直接查看到 Hadoop 控制台状态，显示两个 namenode 节点都处于 <code>standby</code> 状态中，并执行手动 failover :<code>hdfs haadmin -failover nn02 nn01</code>，此时会提示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failover from nn02 to nn01 successful</span><br></pre></td></tr></table></figure>

<p>但查看 namenode 1 节点的控制台中可以发现已经将 nn01 切换为 <code>active</code> 状态了，而 namenode 2 则仍然处于 standby 状态</p>
<h5 id="自动-Failover"><a href="#自动-Failover" class="headerlink" title="自动 Failover"></a>自动 Failover</h5><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/499881401229591.png"><br>在此前我们提到过 Failover 即故障切换和 Hadoop HA 主要是为了应对脑裂现象，而脑裂现象主要由 Namenode 所产生。在这里就需要引入 zkfc 的概述，zkfc 主要是检测 Hadoop HA 集群中处于 active 状态的 namenode 是否宕机，如果宕机了则会迅速的将 standby 状态的 namenode 切换为 active ，并将当前已经宕机的 namenode kill，以防止脑裂现象的出现，这也是 Failover 核心所解决的问题。</p>
<p>本地的测试环境中，通常机器的性能不是很高，那么就会遇到 zkfc 启动不起来的问题，也就是超过 5s 连接不上 Zookeeper 就自动推出，那么可以在 <code>core-site.xml</code> 中加入下述配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;ha.zookeeper.session-timeout.ms&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;30000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.ha.automatic-fallover.enabled&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn01:2181,nn02:2181,dn01:2181,dn02:2181,dn03:2181&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>Info</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>ha.zookeeper.session-timeout.ms</td>
<td>设置 zkfc 连接 Zookeeper 的延迟时间</td>
</tr>
<tr>
<td>2</td>
<td>dfs.ha.automatic-fallover.enabled</td>
<td>启动自动 failover</td>
</tr>
<tr>
<td>3</td>
<td>ha.zookeeper.quorum</td>
<td>ZooKeeper 集群访问地址</td>
</tr>
</tbody></table>
<p>在所有节点中启动 journalnode: <code>hdfs --daemon start journalnode</code> ，以及所有 namenode 节点中启动 zkfc: <code>hdfs --daemon start zkfc</code></p>
<blockquote>
<p>在此之前可能需要使用 <code>hdfs zkfc -formatZK</code> 进行格式化 &#x2F;  <code>hdfs namenode -format</code></p>
</blockquote>
<p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/123930404217458.png"></p>
<p>和 Namenode 主节点中启动：<code>hdfs namenode</code> &#x2F; <code>hdfs --daemon start namenode</code>，然后切换到 nn02 中同步 namenode 让他完全做好成为备份机(standby) 的准备 <code>hdfs namenode -bootstrapStandby</code>，最后在 dn01~dn03 机器中启动 HDFS: <code>start-dfs.sh</code> 那么再次查看 Hadoop 控制台则会在两个 namenode 之间任选一个节点为 active</p>
<h5 id="自启动脚本-1"><a href="#自启动脚本-1" class="headerlink" title="自启动脚本"></a>自启动脚本</h5><p>为方便之后环境的便捷启动，我们需要为 journalnode(nn01<del>dn03) 、zkfs(nn01</del>nn02) 设置自启动，在 <code>/etc/init.d/</code> 目录下新建 hadoop-journalnode 并写入：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">chkconfig:2345 81 09</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">description: hadoop-namenode service</span></span><br><span class="line">RETVAL=0</span><br><span class="line">. /home/hadoop/.bashrc</span><br><span class="line">start() &#123;</span><br><span class="line">    su hadoop -c &quot;hdfs --daemon start journalnode&quot;</span><br><span class="line">&#125;</span><br><span class="line">stop() &#123;</span><br><span class="line">    su hadoop -c &quot;hdfs --daemon start journalnode&quot;</span><br><span class="line">&#125;</span><br><span class="line">case $1 in</span><br><span class="line">start)</span><br><span class="line">    start</span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line">    stop</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">exit $RETVAL</span><br></pre></td></tr></table></figure>


<p>之后在为 zkfs 设置自启动服务，这主要用于 nn01~nn02 机器中，之后同样的赋予他们 <code>+x</code> 权限以及通过 <code>chkconfig</code> 将服务加入到启动项中。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">! /bin/bash</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">chkconfig:2345 98 07</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">description: hadoop-zkfc service</span></span><br><span class="line">RETVAL=0</span><br><span class="line">. /home/hadoop/.bashrc</span><br><span class="line">start() &#123;</span><br><span class="line">    su hadoop -c &quot;hdfs --daemon start zkfc&quot;</span><br><span class="line">&#125;</span><br><span class="line">stop() &#123;</span><br><span class="line">    su hadoop -c &quot;hdfs --daemon stop zkfc&quot;</span><br><span class="line">&#125;</span><br><span class="line">case $1 in</span><br><span class="line">start)</span><br><span class="line">    start</span><br><span class="line">;;</span><br><span class="line">stop)</span><br><span class="line">    stop</span><br><span class="line">;;</span><br><span class="line">esac</span><br><span class="line">exit $RETVAL</span><br></pre></td></tr></table></figure>

<blockquote>
<p>没有将 namenode 和 datanode 设置为自启动服务的主要原因是因为 namenode 需要 active 和 standby 主&#x2F;备机器，所以建议手动启动</p>
</blockquote>
<h2 id="HBase"><a href="#HBase" class="headerlink" title="HBase"></a>HBase</h2><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/369732610211165.png"><br>安装 HBase 的前提是拥有 Zookeeper 虽然 HBase 自带了一个 Zookeeper 但是无法满足 Hadoop 的使用，因此我们通过 <a target="_blank" rel="noopener" href="https://downloads.apache.org/hbase/stable/">https://downloads.apache.org/hbase/stable/</a> 下载 HBase 稳定版本。</p>
<p>在 HBase 中主要通过 <em>HMaster</em> 来管理元数据，也就是 Hadoop 中的 namenode，之后 RegionServer(区域服务器) 负责存储数据，，也就类似于 Hadoop 中的 datanode。同样的，Zookeeper 在此的作用依然是维护节点（需要注意的是 HDFS 是基于完全部署模式的，也就是通过 HDFS 存储数据，在单机模式下直接使用的是普通文件系统来存储数据。）</p>
<blockquote>
<p>这里需要引入一个点是，在 HBase 官方文档中：<a target="_blank" rel="noopener" href="http://hbase.apache.org/book.html#standalone_dist%EF%BC%8C%E5%B0%86">http://hbase.apache.org/book.html#standalone_dist，将</a> HBase 的启动分为了三大类，分别为：独立 HBase、伪分布式和完全分布式集群启动，通常独立 HBase 也被称之为快速上手并理解 HBase 的不二之选。</p>
</blockquote>
<h3 id="hbase-user-create-and-Shell-nopasswd"><a href="#hbase-user-create-and-Shell-nopasswd" class="headerlink" title="hbase user create and Shell nopasswd"></a>hbase user create and Shell nopasswd</h3><p>以 <code>useradd hbase</code> 新建用户 hbase 并为其设置 <code>passwd hbase</code> 密码后通过 <code>sudo chmod u+w /etc/sudoers</code> 将 hbase 添加到 sudoers 列表，向 <code>/etc/sudoers</code> 文件中增加</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## Allow root to run any commands anywhere</span><br><span class="line">root    ALL=(ALL)       ALL</span><br><span class="line">hadoop ALL=NOPASSWD:ALL</span><br><span class="line">hbase ALL=NOPASSWD:ALL</span><br></pre></td></tr></table></figure>

<p>之后切换到 hbase 用户下执行 <code>sudo whoami</code> 来查看 <code>etc/sudoers</code> 是否配置成功(一般是 sudo su root 无需输入密码并返回 root 即完成此配置)</p>
<p>同样的为了应对之后的 HBase 伪分布式模式，我们需要为其配置免密登录，使用 <code>ssh-keygen -t rsa</code> 生成 id_rsa.pub 后以 <code>scp</code> 将自身的 rsa 密钥分发给 nn01，<code>scp .ssh/id_rsa.pub hbase@nn01:/home/hbase/.ssh/nn01_keys</code>，当然也包括自己的，这将使得可以自己 shell 免密连接自己，并设置目录权限：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 700 /home/hbase/</span><br><span class="line">sudo chown hbase:hbase ./.ssh/</span><br><span class="line">cd .ssh/</span><br><span class="line">cat dn01_keys dn02_keys dn03_keys nn01_keys nn02_keys &gt;&gt; authorized_keys</span><br><span class="line">sudo chmod 700 authorized_keys</span><br></pre></td></tr></table></figure>

<blockquote>
<p>之后在通过 scp 将 authorized_keys 分发到 nn01~dn03 的 <code>/.ssh</code> 文件夹中，切记也为其赋予 700 权限</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo chmod 700 /home/hbase/</span><br><span class="line">sudo chown hbase:hbase ./.ssh/</span><br><span class="line">cd .ssh/</span><br><span class="line">sudo chmod 700 authorized_keys</span><br></pre></td></tr></table></figure>

<h3 id="Java-bashrc-and-HBase-install"><a href="#Java-bashrc-and-HBase-install" class="headerlink" title="Java bashrc and HBase install"></a>Java bashrc and HBase install</h3><p>在 <a target="_blank" rel="noopener" href="https://downloads.apache.org/hbase/stable/">https://downloads.apache.org/hbase/stable/</a> 内下载一个稳定版本的 HBase 并在节点机器中使用 <code>wgethttps://downloads.apache.org/hbase/2.3.7/</code> 进行下载并直接使用 <code>sudo mv hbase-2.3.7 /usr/local/hbase</code> 移动到 &#x2F;usr&#x2F;local 目录下。</p>
<p>最后我们还需要通过<code>sudo vi ~/.bashrc</code> 向用户变量内添加 JDK 所在位置和 HBase 的环境变量，然后使用 <code>source ~/.bashrc</code> 刷新即可：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/jdk1.8.0_202</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"></span><br><span class="line"># hbase</span><br><span class="line">export HBASE_HOME=/usr/local/hbase</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure>

<h3 id="单机模式"><a href="#单机模式" class="headerlink" title="单机模式"></a>单机模式</h3><p>进入到 <code>/usr/local/hbase</code> 目录下追加或修改 <code>hbase.rootdir</code> 和 <code>hbase.zookeeer.property.dataDir</code> 配置：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;./tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:///home/hbase/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>单机模式下我们启动了 HBase 自带的 Zookeeper</p>
</blockquote>
<p>这个操作只需要在单个节点中进行测试，因为只是单机模式，会临时使用到 <code>/home/hbase/hbase</code> 和 <code>/home/hbase/zookeeper</code> 目录</p>
<p>接下来通过 <code>start-hbase.sh</code> 来启动 hbae，<code>jps</code> 查看进程正常启动后由 <code>hbase shell</code> 来连接到 hbase，并进行建表(create)、插入(put)、查询(scan) 等三个测试：</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">hbase(main):<span class="number">001</span>:<span class="number">0</span><span class="operator">&gt;</span> <span class="keyword">create</span> <span class="string">&#x27;testTable&#x27;</span>,<span class="string">&#x27;testFamily&#x27;</span></span><br><span class="line">Created <span class="keyword">table</span> testTable</span><br><span class="line">Took <span class="number">3.0652</span> seconds</span><br><span class="line"><span class="operator">=</span><span class="operator">&gt;</span> Hbase::<span class="keyword">Table</span> <span class="operator">-</span> testTable</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">002</span>:<span class="number">0</span><span class="operator">&gt;</span> put <span class="string">&#x27;testTable&#x27;</span>,<span class="string">&#x27;title&#x27;</span>,<span class="string">&#x27;testFamily:heyinfo&#x27;</span>,<span class="string">&#x27;hello,hbase&#x27;</span></span><br><span class="line">Took <span class="number">0.8718</span> seconds</span><br><span class="line"></span><br><span class="line">hbase(main):<span class="number">003</span>:<span class="number">0</span><span class="operator">&gt;</span> scan <span class="string">&#x27;testTable&#x27;</span></span><br><span class="line"><span class="type">ROW</span>                                                              <span class="keyword">COLUMN</span><span class="operator">+</span>CELL</span><br><span class="line"> title                                                           <span class="keyword">column</span><span class="operator">=</span>testFamily:heyinfo, <span class="type">timestamp</span><span class="operator">=</span><span class="number">2021</span><span class="number">-11</span><span class="number">-24</span>T15:<span class="number">31</span>:<span class="number">45.381</span>, <span class="keyword">value</span><span class="operator">=</span>hello,hbase</span><br><span class="line"><span class="number">1</span> <span class="type">row</span>(s)</span><br><span class="line">Took <span class="number">0.2130</span> seconds</span><br></pre></td></tr></table></figure>

<p>当一切完成后我们可通过 <code>stop-hbase.sh</code> 来停止单机模式的 HBase 并 <code>rm -rf /home/hbase/hbase /home/hbase/zookeeper/</code> 删除掉 HBase 在启动之前自动建立的文件夹。</p>
<p>在这里我们需要引入一个 HBase 对于伪分布式的概念，伪分布式很类似完全分布式，但是他是介于 HDFS 为非 HA 状态的，音译仅此将此模式用于原型设计和测试目的，无法用于开发环境和性能评估，我们直接进入完全分布式模式。</p>
<h3 id="完全分布式"><a href="#完全分布式" class="headerlink" title="完全分布式"></a>完全分布式</h3><p><img src="https://49812933408852955071488026628034-1301075051.cos.ap-nanjing.myqcloud.com/markdown/databases/hbash/2.hadoop+zookeeper+hbase.md/423330101211166.png"><br>默认情况下 HBase 在独立模式（单机模式）下运行，以提供最小规模测试(同样包含了非分布式)，对于生产环境加以使用分布式模式，在分布式模式下 HBase 守护程序将会在多个实例集群中服务器运行，但需要注意的完全分布式需要 HDFS 为 HA 模式即可，之后记得在 <code>hbase-env.sh</code> 文件中关闭 HBase 自带的 Zookeeper:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Tell HBase whether it should manage it&#x27;s own instance of ZooKeeper or not.</span><br><span class="line"> export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure>

<p>之后通过<code>sudo groupadd supergroup</code> 建立 supergroup 用户组，然后将 hbase 用户加入到该组中 <code>sudo groupmems -g supergroup -a hbase</code> ，这也是 hdfs 所默认的超级用户组，也就是超级用户，可以无限制权限访问的特殊用户，之后为 Hbase 建立日志文件存储目录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir /data/logs/hbase</span><br><span class="line">sudo chown hbase:hbase /data/logs/hbase</span><br></pre></td></tr></table></figure>
<p>HBase 会根据 HDFS 的客户端配置来做册罗调整，而让 HBase 读取到 HDFS 最为直接的方法就是把 <code>HADOOP__CONF_DIR</code> 的配置文件目录地址添加到 <code>HBASE_CLASSPATH</code> 中，以及 hbase 的日志文件夹配置</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Extra Java CLASSPATH elements.  Optional.</span><br><span class="line"> export HBASE_CLASSPATH=/usr/local/hadoop/etc/hadoop</span><br><span class="line"></span><br><span class="line"># Where log files are stored.  $HBASE_HOME/logs by default.</span><br><span class="line"> export HBASE_LOG_DIR=/data/logs/hbase</span><br></pre></td></tr></table></figure>

<p>在 <code>hbase-site.xml</code> 中增加并修改 <code>hbase.cluster.distributed</code> 为 true 以开启 HBase 分布式启模式启动：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">  &lt;!--</span><br><span class="line">    The following properties are set for running HBase as a single process on a</span><br><span class="line">    developer workstation. With this configuration, HBase is running in</span><br><span class="line">    &quot;stand-alone&quot; mode and without a distributed file system. In this mode, and</span><br><span class="line">    without further configuration, HBase and ZooKeeper data are stored on the</span><br><span class="line">    local filesystem, in a path under the value configured for `hbase.tmp.dir`.</span><br><span class="line">    This value is overridden from its default value of `/tmp` because many</span><br><span class="line">    systems clean `/tmp` on a regular basis. Instead, it points to a path within</span><br><span class="line">    this HBase installation directory.</span><br><span class="line"></span><br><span class="line">    Running against the `LocalFileSystem`, as opposed to a distributed</span><br><span class="line">    filesystem, runs the risk of data integrity issues and data loss. Normally</span><br><span class="line">    HBase will refuse to run in such an environment. Setting</span><br><span class="line">    `hbase.unsafe.stream.capability.enforce` to `false` overrides this behavior,</span><br><span class="line">    permitting operation. This configuration is for the developer workstation</span><br><span class="line">    only and __should not be used in production!__</span><br><span class="line"></span><br><span class="line">    See also https://hbase.apache.org/book.html#standalone_dist</span><br><span class="line">  --&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.tmp.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;./tmp&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;false&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.rootdir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://mycluster/hbase&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">  &lt;property&gt;</span><br><span class="line">    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;nn01,nn02,dn01,dn02,dn03&lt;/value&gt;</span><br><span class="line">  &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>Id</th>
<th>Name</th>
<th>info</th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>hbase.cluster.distributed</td>
<td>告诉 hbase 开启了分布式模式启动</td>
</tr>
<tr>
<td>2</td>
<td>hbase.rootdir</td>
<td>HBase 的根存储目录，其中 mycluster 为集群的 namenode，如果是伪分布式模式可以替换为机器的 namenode</td>
</tr>
<tr>
<td>3</td>
<td>hbase.zookeeper.quorum</td>
<td>Zookeeper 集群地址</td>
</tr>
</tbody></table>
<p>然后将上述配置推送&#x2F;复制到所有节点后，在 nn01 节点(任意节点都可在作为 Master )作为 Master 执行 <code>hbase-daemon.sh start master</code>，之后查看 jps HMaster 是否启动，在其余的集群中(nn01~dn02) 启动 RegionServer:<code>hbase-daemon.sh start regionserver</code>，然后浏览器访问 <code>&lt;master&gt;:16010</code> 即可，hbase 模式下的服务为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">9841 HRegionServer</span><br><span class="line">10437 Jps</span><br><span class="line">9548 HMaster</span><br></pre></td></tr></table></figure>


	

	

</article>





	<span class="different-posts">📖 <a href="/page/22">more posts</a> 📖</span>



	</main>

	<footer class="footer">
	<div class="footer-content">
		
	      <div class="footer__element">
	<p>欢迎来到我的 blog <br><br> 通过 <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a>+<a target="_blank" rel="noopener" href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a> 进行构建的，存放在 <a target="_blank" rel="noopener" href="https://github.com/vendanges/vendanges.github.io">Github</a> 上。</p>
</div>

	    
	      <div class="footer__element">
	<h5>Check out</h5>
	<ul class="footer-links">
		<li class="footer-links__link"><a href="/archives">Archive</a></li>
		
		  <li class="footer-links__link"><a href="/atom.xml">RSS</a></li>
	    
		<li class="footer-links__link"><a href="/about">about page</a></li>
		<li class="footer-links__link"><a href="/tags">Tags</a></li>
		<li class="footer-links__link"><a href="/categories">Categories</a></li>
	</ul>
</div>

	    

		<div class="footer-credit">
			<span>© 2022 John Doe | Powered by <a target="_blank" rel="noopener" href="https://hexo.io/">Hexo</a> | Theme <a target="_blank" rel="noopener" href="https://github.com/HoverBaum/meilidu-hexo">MeiliDu</a></span>
		</div>

	</div>


</footer>



</body>

</html>
